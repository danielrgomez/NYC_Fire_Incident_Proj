{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1b848-e3c5-4d27-b193-70a3041af962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#API Key ID - 8frxx42pw5tkoeebz9kyzmd7e\n",
    "#API Key Secret - 34i7ii0vg37y7r3zssml3m6kljoqrqd7ucjipijnop4pgpmajo\n",
    "#Token - K0nAnd8O1CS0ggdOb8OumLj3H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42514d9a-9e37-4a2d-aa0b-93a3b37cd315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from sodapy import Socrata\n",
    "from sqlalchemy import create_engine\n",
    "from time import time\n",
    "import argparse\n",
    "#import psycopg2\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt\n",
    "import requests\n",
    "import pyspark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b28180-0202-4a2b-8afa-a2f5bc58db43",
   "metadata": {},
   "source": [
    "## Extract Via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "143bf28d-3b35-4664-a843-486709c4d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Socrata(\"data.cityofnewyork.us\", \"xoIfIdDlHq6gGzxqLqbUeMpsG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a9bf86a-7dc6-447d-b55e-43f64246b8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to API\n"
     ]
    }
   ],
   "source": [
    "@retry(wait=wait_exponential(multiplier=2, min=2, max=16), stop=stop_after_attempt(5))\n",
    "def get_data_from_api(client,data_set,limit_rows):\n",
    "    results = client.get(data_set,limit=limit_rows)\n",
    "    return results\n",
    "try:\n",
    "    #results = client.get(\"8m42-w767\", limit=50)\n",
    "    results = get_data_from_api(client,\"8m42-w767\",10000)\n",
    "    print(\"Connected to API\")\n",
    "    \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Failed to fetch data from API: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8154a360-c791-4df7-aaa7-0761d78590e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Pandas Transformations ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d866251-5081-453f-a59e-d8c1ae95b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99b194b-afb3-456f-8a0c-4e381dc26b50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b157cd1-6ea3-42b3-9787-ebd38a2d27d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53bc758-957e-4d9a-aca5-899c1a0eba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting fields to correct data types\n",
    "#Date conversion\n",
    "df.incident_datetime = pd.to_datetime(df.incident_datetime)\n",
    "df.first_assignment_datetime = pd.to_datetime(df.first_assignment_datetime)\n",
    "df.first_activation_datetime = pd.to_datetime(df.first_activation_datetime)\n",
    "df.incident_close_datetime = pd.to_datetime(df.incident_close_datetime)\n",
    "#df.first_on_scene_datetime = pd.to_datetime(df.first_on_scene_datetime)\n",
    "\n",
    "#Float conversion\n",
    "df.dispatch_response_seconds_qy = df.dispatch_response_seconds_qy.astype(float)\n",
    "df.incident_response_seconds_qy = df.incident_response_seconds_qy.astype(float)\n",
    "df.incident_travel_tm_seconds_qy = df.incident_travel_tm_seconds_qy.astype(float)\n",
    "df.engines_assigned_quantity = df.engines_assigned_quantity.astype(float)\n",
    "df.ladders_assigned_quantity = df.ladders_assigned_quantity.astype(float)\n",
    "df.other_units_assigned_quantity = df.other_units_assigned_quantity.astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32df4d8c-c61e-4e8c-8068-fdf815cd7402",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f144c5-fdef-4ad1-87c3-6005aa8ea013",
   "metadata": {},
   "source": [
    "## PySpark Transformations ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd2cdef4-fd93-4977-9fb8-ba9773ec4b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.sql.functions import to_timestamp, to_date\n",
    "spark = SparkSession.builder.appName(\"Transformations_NYC_Fire_Incidents\").getOrCreate()\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56b0d55d-5c99-451b-a084-d8cba8fb4a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90602e9b-9966-43b4-83aa-1ed407e4b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "as_a_string = str(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ddb9c70-fe02-4d5b-a852-f437e94d9ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = str(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef416733-7e62-4ec9-b5d0-a83533410e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e91d897a-09bc-402e-9fa8-1854d1f3cf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(spark.sparkContext.parallelize([results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c86931-4b96-4399-a3f9-9a97631d9d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to clean null values, The function takes in the following paramters: pyspark dataframe, column name to clean, each of the broughs values to switch to.\n",
    "def clean_null_values(df,column_name_to_clean,bronx_value,brooklyn_value,manhattan_value,queens_value,staten_value):\n",
    "    df = df.withColumn(\n",
    "    column_name_to_clean,\n",
    "    when(col(column_name_to_clean).isNull() & (col(\"alarm_box_borough\") == \"BRONX\"),bronx_value)\n",
    "    .when(col(column_name_to_clean).isNull() & (col(\"alarm_box_borough\") == \"BROOKLYN\"),brooklyn_value)\n",
    "    .when(col(column_name_to_clean).isNull() & (col(\"alarm_box_borough\") == \"MANHATTAN\"),manhattan_value)\n",
    "    .when(col(column_name_to_clean).isNull() & (col(\"alarm_box_borough\") == \"QUEENS\"),queens_value)\n",
    "    .when(col(column_name_to_clean).isNull() & (col(\"alarm_box_borough\") == \"RICHMOND / STATEN ISLAND\"),staten_value)\n",
    "    .otherwise(col(column_name_to_clean))\n",
    ")\n",
    "    return df\n",
    "\n",
    "#The values presented below correspond to the first entry identified for each field within their respective boroughs. For instance, in the case of the Bronx, the first zip code encountered in the dataset was 10451.  \n",
    "#For the null values, it is assumed that the newly assigned values will approximate the actual values as closely as possible.\n",
    "df = clean_null_values(df,\"zipcode\",10451,11201,10001,11004,10301)\n",
    "df = clean_null_values(df,\"policeprecinct\",40,60,1,100,120)\n",
    "df = clean_null_values(df,\"citycouncildistrict\",8,33,1,19,49)\n",
    "df = clean_null_values(df,\"communitydistrict\",201,301,101,401,501)\n",
    "df = clean_null_values(df,\"communityschooldistrict\",7,13,1,7,31)\n",
    "df = clean_null_values(df,\"congressionaldistrict\",13,7,7,3,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf6c0ae-20b0-4fff-be34-027300e9b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation purposes run one by one\n",
    "df.where(df[\"policeprecinct\"].isNull()).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").count()\n",
    "df.where(df[\"citycouncildistrict\"].isNull()).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").count()\n",
    "df.where(df[\"communitydistrict\"].isNull()).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").count()\n",
    "df.where(df[\"communityschooldistrict\"].isNull()).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").count()\n",
    "df.where(df[\"congressionaldistrict\"].isNull()).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3d26f3-de0f-43be-babf-6638b0d34e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to date time\n",
    "df = df.withColumn(\"incident_datetime\", to_timestamp(df[\"incident_datetime\"]))\n",
    "df = df.withColumn(\"first_assignment_datetime\", to_timestamp(df[\"first_assignment_datetime\"]))\n",
    "df = df.withColumn(\"first_activation_datetime\", to_timestamp(df[\"first_activation_datetime\"]))\n",
    "df = df.withColumn(\"incident_close_datetime\", to_timestamp(df[\"incident_close_datetime\"]))\n",
    "\n",
    "#Convert to floats\n",
    "df = df.withColumn(\"dispatch_response_seconds_qy\", df[\"dispatch_response_seconds_qy\"].cast(\"float\"))\n",
    "df = df.withColumn(\"incident_response_seconds_qy\", df[\"incident_response_seconds_qy\"].cast(\"float\"))\n",
    "df = df.withColumn(\"incident_travel_tm_seconds_qy\", df[\"incident_travel_tm_seconds_qy\"].cast(\"float\"))\n",
    "df = df.withColumn(\"engines_assigned_quantity\", df[\"engines_assigned_quantity\"].cast(\"float\"))\n",
    "df = df.withColumn(\"ladders_assigned_quantity\", df[\"ladders_assigned_quantity\"].cast(\"float\"))\n",
    "df = df.withColumn(\"other_units_assigned_quantity\", df[\"other_units_assigned_quantity\"].cast(\"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef445e5d-da37-4fd5-a8e3-fa365e567641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to categorize the response times and other quantity type fields. This will be used to aggregate data for OLAP usage.\n",
    "from pyspark.sql.functions import max\n",
    "from pyspark.sql.functions import min\n",
    "\n",
    "def categorize_float_fields(df,column_name,none,very_low,low,medium,high,very_high):\n",
    "    # Returns the max response\n",
    "    max_quantity = df.agg(max(column_name).alias(\"max_response_alias\")).collect()[0]\n",
    "    max_quantity = max_quantity[\"max_response_alias\"] \n",
    "\n",
    "    # Returns the min quantity\n",
    "    min_quantity = df.agg(min(column_name).alias(\"min_response_alias\")).collect()[0]\n",
    "    min_quantity = min_quantity[\"min_response_alias\"]\n",
    "\n",
    "    #Calculates the category interval this is to determine the intervals between each category. 5 Categories were chosen.\n",
    "    category_interval = (max_quantity - min_quantity) / 5\n",
    "    \n",
    "    #Categorizes each quantity column using the range between the max and min\n",
    "    df = df.withColumn(\n",
    "        \"category_\" + column_name,\n",
    "        when((col(column_name) == 0),none)\n",
    "        .when((col(column_name) > 0) & (col(column_name) <= category_interval),very_low)\n",
    "        .when((col(column_name) > category_interval) & (col(column_name) <= (category_interval*2)),low)\n",
    "        .when((col(column_name) > (category_interval*2)) & (col(column_name) <= (category_interval*3)),medium)\n",
    "        .when((col(column_name) > (category_interval*3)) & (col(column_name) <= (category_interval*4)),high)\n",
    "        .otherwise(very_high)\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = categorize_float_fields(df,\"dispatch_response_seconds_qy\",\"None\",\"Very Low\",\"Low\",\"Medium\",\"High\",\"Very High\")\n",
    "df = categorize_float_fields(df,\"incident_response_seconds_qy\",\"None\",\"Very Low\",\"Low\",\"Medium\",\"High\",\"Very High\")\n",
    "df = categorize_float_fields(df,\"incident_travel_tm_seconds_qy\",\"None\",\"Very Low\",\"Low\",\"Medium\",\"High\",\"Very High\")\n",
    "df = categorize_float_fields(df,\"engines_assigned_quantity\",\"None\",\"Minimal\",\"Limited\",\"Moderate\",\"Substantial\",\"Abundant\")\n",
    "df = categorize_float_fields(df,\"ladders_assigned_quantity\",\"None\",\"Minimal\",\"Limited\",\"Moderate\",\"Substantial\",\"Abundant\")\n",
    "df = categorize_float_fields(df,\"other_units_assigned_quantity\",\"None\",\"Minimal\",\"Limited\",\"Moderate\",\"Substantial\",\"Abundant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21806fff-d413-479f-b206-9b63f7726e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "#Calculating Averages for esponse times by each borough\n",
    "total_avg_dispatch_response_seconds_qy_per_borough = df.groupBy(\"alarm_box_borough\").agg(avg(\"dispatch_response_seconds_qy\")).alias(\"total_avg_dispatch_response_seconds_qy_per_borough\")\n",
    "total_incident_travel_tm_seconds_qy_per_borough = df.groupBy(\"alarm_box_borough\").agg(avg(\"incident_travel_tm_seconds_qy\")).alias(\"total_incident_travel_tm_seconds_qy_per_borough\")\n",
    "total_incident_response_seconds_qy_per_borough = df.groupBy(\"alarm_box_borough\").agg(avg(\"incident_response_seconds_qy\")).alias(\"total_incident_response_seconds_qy_per_borough\")\n",
    "\n",
    "# Join the average back to the original DataFrame\n",
    "df = df.join(total_avg_dispatch_response_seconds_qy_per_borough, on=\"alarm_box_borough\", how=\"left\")\n",
    "df = df.join(total_incident_travel_tm_seconds_qy_per_borough, on=\"alarm_box_borough\", how=\"left\")\n",
    "df = df.join(total_incident_response_seconds_qy_per_borough, on=\"alarm_box_borough\", how=\"left\")\n",
    "\n",
    "\n",
    "\n",
    "#Renaming Columns and Casting to Float Types\n",
    "def clean_column(df,column_name_before,column_name_after):\n",
    "    df = df.withColumnRenamed(column_name_before, column_name_after)\n",
    "\n",
    "    df = df.withColumn(column_name_after, col(column_name_after).cast(\"float\"))\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = clean_column(df,\"avg(dispatch_response_seconds_qy)\",\"total_avg_dispatch_response_seconds_qy_per_borough\")\n",
    "df = clean_column(df,\"avg(incident_travel_tm_seconds_qy)\",\"total_avg_incident_travel_tm_seconds_qy_per_borough\")\n",
    "df = clean_column(df,\"avg(incident_response_seconds_qy)\",\"total_avg_incident_response_seconds_qy_per_borough\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a1eeb7-6164-42ee-a51e-1f7b57b44731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Resources Assigned to an Incident. Total quantity of Engines, Ladders, and Other Units.\n",
    "df = df.withColumn(\n",
    "    \"total_resources_assigned_quantity\",\n",
    "    col(\"engines_assigned_quantity\") + col(\"ladders_assigned_quantity\") + col(\"other_units_assigned_quantity\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa969d-b267-48ea-960a-51f6e7f9e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b382d-3449-4abb-bdd2-3a08a1735568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b14a4c3-a9eb-410f-8902-47c19f47cdd5",
   "metadata": {},
   "source": [
    "#### Official Transformations ^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b947b2bd-e420-4c16-89cd-a80ec237152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be3e929-d57f-4a79-b91b-64679d8b83c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c85c44-850b-42f5-9cd2-90d0c307108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_incident_response_seconds_qy_per_borough.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e971b1-b37d-4fbb-aa60-5ffde471da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b1193-2b2f-4f85-a767-ca72021b65f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0a8516-69f3-45fe-a6a6-7caf7c4bc3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aa131d-66dc-4944-991f-fcd59956cde0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f435387-fb1b-4b87-8496-9e0f41687ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9336984-d8fe-4f8f-b49a-c9c9efc9c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"dispatch_response_seconds_qy\",\"incident_travel_tm_seconds_qy\",\"total_response_time\",\"incident_response_seconds_qy\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363367f0-f250-4857-8813-0eb7976c0712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfc3f09-f7fd-46bc-8c6b-8830ef5070bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaaf456-dd5c-4e71-a14b-109a4c74c4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeddffea-f368-4b91-9619-9e0d8614f864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070ddf0-cc0a-408a-a8ba-9b9143495326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8340ccee-2260-4c63-87df-28cfddd74320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max\n",
    "from pyspark.sql.functions import min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beb7a70-5352-4d66-86a5-7169c9375b37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# category_ranges_dispatch_response_seconds_qy\n",
    "max_dispatch_response_seconds_qy = df.agg(max(\"dispatch_response_seconds_qy\").alias(\"max_dispatch_response_seconds_qy\")).collect()[0]\n",
    "max_dispatch_response_seconds_qy = max_dispatch_response_seconds_qy[\"max_dispatch_response_seconds_qy\"] \n",
    "\n",
    "min_dispatch_response_seconds_qy = df.agg(min(\"dispatch_response_seconds_qy\").alias(\"max_dispatch_response_seconds_qy\")).collect()[0]\n",
    "min_dispatch_response_seconds_qy = min_dispatch_response_seconds_qy[\"max_dispatch_response_seconds_qy\"]\n",
    "\n",
    "category_ranges_dispatch_response_seconds_qy = (max_dispatch_response_seconds_qy - min_dispatch_response_seconds_qy) / 5\n",
    "\n",
    "#Categorize dispatch_response_seconds_qy Very Low, Low, Medium, High, Very High\n",
    "df = df.withColumn(\n",
    "    \"category_dispatch_response_seconds_qy\",\n",
    "    when((col(\"dispatch_response_seconds_qy\") >= 0) & (col(\"dispatch_response_seconds_qy\") <= category_ranges_dispatch_response_seconds_qy),\"Very Low\")\n",
    "    .when((col(\"dispatch_response_seconds_qy\") > category_ranges_dispatch_response_seconds_qy) & (col(\"dispatch_response_seconds_qy\") <= (category_ranges_dispatch_response_seconds_qy*2)),\"Low\")\n",
    "    .when((col(\"dispatch_response_seconds_qy\") > (category_ranges_dispatch_response_seconds_qy*2)) & (col(\"dispatch_response_seconds_qy\") <= (category_ranges_dispatch_response_seconds_qy*3)),\"Medium\")\n",
    "    .when((col(\"dispatch_response_seconds_qy\") > (category_ranges_dispatch_response_seconds_qy*3)) & (col(\"dispatch_response_seconds_qy\") <= (category_ranges_dispatch_response_seconds_qy*4)),\"High\")\n",
    "    .otherwise(\"Very High\")\n",
    "    #.when(col(\"dispatch_response_seconds_qy\") > (category_ranges_dispatch_response_seconds_qy*4) & (col(\"dispatch_response_seconds_qy\") <= (category_ranges_dispatch_response_seconds_qy*5)),\"Very High\")\n",
    ")\n",
    "\n",
    "df.select(df[\"category_dispatch_response_seconds_qy\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9996c7fd-d820-440b-bc4a-ac6760c3874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select([\"category_other_units_assigned_quantity\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7d5b8-2bd5-42dd-a897-574e5e71f2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae3656-e1be-4cb1-8e9d-5e099768d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"category_engines_assigned_quantity\"].select()\n",
    "df.orderBy(df[\"engines_assigned_quantity\"].desc()).select(df[\"category_engines_assigned_quantity\"],df[\"engines_assigned_quantity\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d183d-377f-4f10-942c-e261f98e3dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01316b2-a71f-4776-9df9-9ab749a82459",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('Temp_Tbl')\n",
    "max_dispatch_response_seconds_qy = spark.sql(\"SELECT max(dispatch_response_seconds_qy) FROM Temp_Tbl\")\n",
    "min_dispatch_response_seconds_qy = spark.sql(\"SELECT max(dispatch_response_seconds_qy) FROM Temp_Tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed2c7a0-eb50-48d7-b6fc-1064ca975b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dispatch_response_seconds_qy.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c43bbb-450b-4b48-ac83-868c754af69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dispatch_response_seconds_qy.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d72f6c-8f6e-4e33-a643-ccec0521764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dispatch_response_seconds_qy.show() / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f461359-1f21-4194-a042-9eb163436650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(df[\"dispatch_response_seconds_qy\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac24d7c-f3a2-46ff-8c78-b3f1f86e4aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length\n",
    "df_with_char_count = df.withColumn(\"char_count\", length(df[\"zipcode\"]))\n",
    "df_with_char_count.where(df_with_char_count[\"char_count\"]>5).select(\"zipcode\",\"char_count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03cf31-2f0b-47a8-821f-faa73a039133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4b077c-b481-4f32-b41b-e808e75d14c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"first_assignment_datetime\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d4f652-cd56-4afd-9864-9c07f451357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('Temp_Tbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263a84ae-0adc-4163-b8bd-8148dc62bd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = spark.sql(\"SELECT * FROM Fire_Incidents_Temp_Tbl where zipcode is null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5225e53f-25f0-451f-b56c-68a768fbde01",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de1233-5d56-41af-b1cc-8ef02aed589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = spark.sql(\"SELECT starfire_incident_id,zipcode,alarm_box_borough FROM Fire_Incidents_Temp_Tbl where starfire_incident_id = 2100422620120017\")\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f8351-9a50-404d-8d93-1bf91aae7e14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.select(\"starfire_incident_id\", \"zipcode\",\"alarm_box_borough\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fdf4a7-a08a-4ca2-8751-7d692469cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df[\"starfire_incident_id\"]==2100422620120017).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f043cea-0b55-418c-bc37-f60c3706ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df[\"starfire_incident_id\"]==2100422620120017).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09356939-7b28-4d1f-8b83-57f7d36b600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df[\"zipcode\"].isNull()).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16237aec-4a91-4ea6-a2fd-1f8a83009fd0",
   "metadata": {},
   "source": [
    "## Postgres Load ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86692e-3d35-498a-8f92-3cae086a7cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the engine postgressql://username:password@host:port/db_name\n",
    "username = 'root'\n",
    "password = 'root'\n",
    "host = \"fire_incidents_db\"\n",
    "port = 5432\n",
    "database = \"fire_incidents\"\n",
    "engine = create_engine(f'postgresql+psycopg2://{username}:{password}@{host}:{port}/{database}')\n",
    "#engine = create_engine('postgresql://root:root@fire_incidents_db:5432/fire_incidents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18242819-4e37-48b3-9bfe-732da556686a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Defines a schema, names it to yellow_taxi_data, and then assigns it to postgres\n",
    "print(pd.io.sql.get_schema(df,name='fire_incidents_schema',con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932c5c2-e3a3-421f-85b5-dc215eafce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates the table in postgres with only the field names. Name = yellow_taxi_data, Engine is the postgres database, if_exists = 'replace' if a table already exists with this name it will replace it\n",
    "df.head(n=0).to_sql(name='fire_incidents_tbl',con=engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0398cc2b-cb01-461c-8c0a-0ebf092da2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "batchsize = 1000\n",
    "def create_batches_of_rows(dataframe,batchsize):\n",
    "    start = 0\n",
    "    while start < len(df) + 1:\n",
    "        yield df.iloc[start:start + batchsize]\n",
    "        start += batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab342479-2126-4871-87f8-fc2e65e0eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a list of batches. Parses the dataframe and the batchsize through the create_batches_of_rows function and sets the variable batches to the list\n",
    "batches = list(create_batches_of_rows(df,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3260e20-ba46-471d-8666-4d8c85fec800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loops through each one of the batches and appends the batch to the postgressql database.\n",
    "counter = 1\n",
    "for batch in batches:\n",
    "    batch.to_sql(name='fire_incidents_tbl', con=engine, if_exists='append')\n",
    "    print(f'Batch Loaded..... {counter}')\n",
    "    counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3abf44-0e46-47f4-a918-9ef65610a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'root'\n",
    "password = 'root'\n",
    "host = \"fire_incidents_db\"\n",
    "port = 5432\n",
    "database = \"fire_incidents\"\n",
    "print(f'postgresql+psycopg2://{username}:{password}@{host}:{port}/{database}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
