{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42514d9a-9e37-4a2d-aa0b-93a3b37cd315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from sodapy import Socrata\n",
    "from sqlalchemy import create_engine\n",
    "from time import time\n",
    "import argparse\n",
    "#import psycopg2\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt\n",
    "import requests\n",
    "import pyspark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b28180-0202-4a2b-8afa-a2f5bc58db43",
   "metadata": {},
   "source": [
    "## Extract Via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "143bf28d-3b35-4664-a843-486709c4d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Socrata(\"data.cityofnewyork.us\", \"xoIfIdDlHq6gGzxqLqbUeMpsG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a9bf86a-7dc6-447d-b55e-43f64246b8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to API\n"
     ]
    }
   ],
   "source": [
    "@retry(wait=wait_exponential(multiplier=2, min=2, max=16), stop=stop_after_attempt(5))\n",
    "def get_data_from_api(client,data_set,limit_rows):\n",
    "    results = client.get(data_set,limit=limit_rows)\n",
    "    return results\n",
    "try:\n",
    "    #results = client.get(\"8m42-w767\", limit=50)\n",
    "    results = get_data_from_api(client,\"8m42-w767\",10000)\n",
    "    print(\"Connected to API\")\n",
    "    \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Failed to fetch data from API: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d89f173-6636-4a44-ae98-0750faafd109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "#Save to temp folder\n",
    "current_dir = os.getcwd()\n",
    "temp_folder = os.path.join(current_dir, \"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e8eb5e-42d8-4fc7-8dcd-6dae43e00566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the temp folder if it doesn't exist\n",
    "if not os.path.exists(temp_folder):\n",
    "    os.makedirs(temp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fef43a2-7ba3-45b6-a487-9ad8953bafc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the JSON file\n",
    "file_path = os.path.join(temp_folder, \"output.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b6bdc6-820a-41be-8400-a915d41addc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the JSON output to the file\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(results, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8154a360-c791-4df7-aaa7-0761d78590e8",
   "metadata": {},
   "source": [
    "## Pandas Transformations ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d866251-5081-453f-a59e-d8c1ae95b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f99b194b-afb3-456f-8a0c-4e381dc26b50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starfire_incident_id</th>\n",
       "      <th>incident_datetime</th>\n",
       "      <th>alarm_box_borough</th>\n",
       "      <th>alarm_box_number</th>\n",
       "      <th>alarm_box_location</th>\n",
       "      <th>incident_borough</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>policeprecinct</th>\n",
       "      <th>citycouncildistrict</th>\n",
       "      <th>communitydistrict</th>\n",
       "      <th>...</th>\n",
       "      <th>first_activation_datetime</th>\n",
       "      <th>incident_close_datetime</th>\n",
       "      <th>valid_dispatch_rspns_time_indc</th>\n",
       "      <th>valid_incident_rspns_time_indc</th>\n",
       "      <th>incident_response_seconds_qy</th>\n",
       "      <th>incident_travel_tm_seconds_qy</th>\n",
       "      <th>engines_assigned_quantity</th>\n",
       "      <th>ladders_assigned_quantity</th>\n",
       "      <th>other_units_assigned_quantity</th>\n",
       "      <th>first_on_scene_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2100404460110002</td>\n",
       "      <td>2021-01-04T00:01:00.000</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>446</td>\n",
       "      <td>3 AVE &amp; ST. MARKS PL</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10003</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-01-04T00:02:00.000</td>\n",
       "      <td>2021-01-04T00:07:00.000</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2100433250140001</td>\n",
       "      <td>2021-01-04T00:01:00.000</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>3325</td>\n",
       "      <td>AVENUE O &amp; E 13 ST</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11230</td>\n",
       "      <td>70</td>\n",
       "      <td>48</td>\n",
       "      <td>314</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-01-04T00:02:00.000</td>\n",
       "      <td>2021-01-04T00:32:00.000</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>170</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-04T00:04:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2100411280150003</td>\n",
       "      <td>2021-01-04T00:01:00.000</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>1128</td>\n",
       "      <td>MOTT AVE &amp; DICKENS ST</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11691</td>\n",
       "      <td>101</td>\n",
       "      <td>31</td>\n",
       "      <td>414</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-01-04T00:02:00.000</td>\n",
       "      <td>2021-01-04T00:05:00.000</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2100416590110004</td>\n",
       "      <td>2021-01-04T00:02:00.000</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>1659</td>\n",
       "      <td>BROADWAY &amp; 153 ST</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10031</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-01-04T00:02:00.000</td>\n",
       "      <td>2021-01-04T00:31:00.000</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>318</td>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-04T00:07:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2100413490110006</td>\n",
       "      <td>2021-01-04T00:02:00.000</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>1349</td>\n",
       "      <td>5 AVE &amp; 112 ST</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10026</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-01-04T00:03:00.000</td>\n",
       "      <td>2021-01-04T00:18:00.000</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>871</td>\n",
       "      <td>834</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-04T00:17:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2100412610150005</td>\n",
       "      <td>2021-01-04T00:06:00.000</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>1261</td>\n",
       "      <td>ALMEDA AVE &amp; B63 ST</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11692</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>414</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-01-04T00:07:00.000</td>\n",
       "      <td>2021-01-04T00:18:00.000</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>341</td>\n",
       "      <td>336</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-04T00:12:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2100479410150006</td>\n",
       "      <td>2021-01-04T00:07:00.000</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>7941</td>\n",
       "      <td>B'WAY &amp; BAXTER AVE</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11373</td>\n",
       "      <td>110</td>\n",
       "      <td>25</td>\n",
       "      <td>404</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-01-04T00:08:00.000</td>\n",
       "      <td>2021-01-04T00:42:00.000</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>307</td>\n",
       "      <td>267</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-04T00:12:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2100425290120007</td>\n",
       "      <td>2021-01-04T00:10:00.000</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>2529</td>\n",
       "      <td>M.L.KING JR BLVD &amp; W 165 ST</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10452</td>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>204</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-01-04T00:11:00.000</td>\n",
       "      <td>2021-01-04T00:16:00.000</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2100402410130006</td>\n",
       "      <td>2021-01-04T00:10:00.000</td>\n",
       "      <td>RICHMOND / STATEN ISLAND</td>\n",
       "      <td>241</td>\n",
       "      <td>BAY &amp; BROAD STS</td>\n",
       "      <td>RICHMOND / STATEN ISLAND</td>\n",
       "      <td>10304</td>\n",
       "      <td>120</td>\n",
       "      <td>49</td>\n",
       "      <td>501</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-01-04T00:11:00.000</td>\n",
       "      <td>2021-01-04T00:16:00.000</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>132</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-04T00:13:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2100417350140004</td>\n",
       "      <td>2021-01-04T00:15:00.000</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>1735</td>\n",
       "      <td>NEW JERSEY AVE &amp; FULTON ST</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11207</td>\n",
       "      <td>75</td>\n",
       "      <td>37</td>\n",
       "      <td>305</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-01-04T00:16:00.000</td>\n",
       "      <td>2021-01-04T00:45:00.000</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>208</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-04T00:18:00.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  starfire_incident_id        incident_datetime         alarm_box_borough  \\\n",
       "0     2100404460110002  2021-01-04T00:01:00.000                 MANHATTAN   \n",
       "1     2100433250140001  2021-01-04T00:01:00.000                  BROOKLYN   \n",
       "2     2100411280150003  2021-01-04T00:01:00.000                    QUEENS   \n",
       "3     2100416590110004  2021-01-04T00:02:00.000                 MANHATTAN   \n",
       "4     2100413490110006  2021-01-04T00:02:00.000                 MANHATTAN   \n",
       "5     2100412610150005  2021-01-04T00:06:00.000                    QUEENS   \n",
       "6     2100479410150006  2021-01-04T00:07:00.000                    QUEENS   \n",
       "7     2100425290120007  2021-01-04T00:10:00.000                     BRONX   \n",
       "8     2100402410130006  2021-01-04T00:10:00.000  RICHMOND / STATEN ISLAND   \n",
       "9     2100417350140004  2021-01-04T00:15:00.000                  BROOKLYN   \n",
       "\n",
       "  alarm_box_number           alarm_box_location          incident_borough  \\\n",
       "0              446         3 AVE & ST. MARKS PL                 MANHATTAN   \n",
       "1             3325           AVENUE O & E 13 ST                  BROOKLYN   \n",
       "2             1128        MOTT AVE & DICKENS ST                    QUEENS   \n",
       "3             1659            BROADWAY & 153 ST                 MANHATTAN   \n",
       "4             1349               5 AVE & 112 ST                 MANHATTAN   \n",
       "5             1261          ALMEDA AVE & B63 ST                    QUEENS   \n",
       "6             7941           B'WAY & BAXTER AVE                    QUEENS   \n",
       "7             2529  M.L.KING JR BLVD & W 165 ST                     BRONX   \n",
       "8              241              BAY & BROAD STS  RICHMOND / STATEN ISLAND   \n",
       "9             1735   NEW JERSEY AVE & FULTON ST                  BROOKLYN   \n",
       "\n",
       "  zipcode policeprecinct citycouncildistrict communitydistrict  ...  \\\n",
       "0   10003              9                   2               103  ...   \n",
       "1   11230             70                  48               314  ...   \n",
       "2   11691            101                  31               414  ...   \n",
       "3   10031             30                   7               109  ...   \n",
       "4   10026             28                   9               110  ...   \n",
       "5   11692            100                  31               414  ...   \n",
       "6   11373            110                  25               404  ...   \n",
       "7   10452             44                  16               204  ...   \n",
       "8   10304            120                  49               501  ...   \n",
       "9   11207             75                  37               305  ...   \n",
       "\n",
       "  first_activation_datetime  incident_close_datetime  \\\n",
       "0   2021-01-04T00:02:00.000  2021-01-04T00:07:00.000   \n",
       "1   2021-01-04T00:02:00.000  2021-01-04T00:32:00.000   \n",
       "2   2021-01-04T00:02:00.000  2021-01-04T00:05:00.000   \n",
       "3   2021-01-04T00:02:00.000  2021-01-04T00:31:00.000   \n",
       "4   2021-01-04T00:03:00.000  2021-01-04T00:18:00.000   \n",
       "5   2021-01-04T00:07:00.000  2021-01-04T00:18:00.000   \n",
       "6   2021-01-04T00:08:00.000  2021-01-04T00:42:00.000   \n",
       "7   2021-01-04T00:11:00.000  2021-01-04T00:16:00.000   \n",
       "8   2021-01-04T00:11:00.000  2021-01-04T00:16:00.000   \n",
       "9   2021-01-04T00:16:00.000  2021-01-04T00:45:00.000   \n",
       "\n",
       "  valid_dispatch_rspns_time_indc valid_incident_rspns_time_indc  \\\n",
       "0                              N                              N   \n",
       "1                              N                              Y   \n",
       "2                              N                              N   \n",
       "3                              N                              Y   \n",
       "4                              N                              Y   \n",
       "5                              N                              Y   \n",
       "6                              N                              Y   \n",
       "7                              N                              N   \n",
       "8                              N                              Y   \n",
       "9                              N                              Y   \n",
       "\n",
       "  incident_response_seconds_qy incident_travel_tm_seconds_qy  \\\n",
       "0                            0                             0   \n",
       "1                          170                           165   \n",
       "2                            0                             0   \n",
       "3                          318                           314   \n",
       "4                          871                           834   \n",
       "5                          341                           336   \n",
       "6                          307                           267   \n",
       "7                            0                             0   \n",
       "8                          132                           127   \n",
       "9                          208                           159   \n",
       "\n",
       "  engines_assigned_quantity ladders_assigned_quantity  \\\n",
       "0                         1                         0   \n",
       "1                         1                         0   \n",
       "2                         1                         0   \n",
       "3                         1                         0   \n",
       "4                         1                         0   \n",
       "5                         1                         0   \n",
       "6                         2                         2   \n",
       "7                         1                         0   \n",
       "8                         1                         0   \n",
       "9                         1                         1   \n",
       "\n",
       "  other_units_assigned_quantity  first_on_scene_datetime  \n",
       "0                             0                      NaN  \n",
       "1                             0  2021-01-04T00:04:00.000  \n",
       "2                             0                      NaN  \n",
       "3                             0  2021-01-04T00:07:00.000  \n",
       "4                             0  2021-01-04T00:17:00.000  \n",
       "5                             0  2021-01-04T00:12:00.000  \n",
       "6                             1  2021-01-04T00:12:00.000  \n",
       "7                             0                      NaN  \n",
       "8                             0  2021-01-04T00:13:00.000  \n",
       "9                             0  2021-01-04T00:18:00.000  \n",
       "\n",
       "[10 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b157cd1-6ea3-42b3-9787-ebd38a2d27d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b4936-cd73-48cc-889d-3f4049046637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows 390 through 400\n",
    "subset = df.iloc[389:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3525c1-1821-4171-8e1c-90785ab73f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53bc758-957e-4d9a-aca5-899c1a0eba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting fields to correct data types\n",
    "#Date conversion\n",
    "df.incident_datetime = pd.to_datetime(df.incident_datetime)\n",
    "df.first_assignment_datetime = pd.to_datetime(df.first_assignment_datetime)\n",
    "df.first_activation_datetime = pd.to_datetime(df.first_activation_datetime)\n",
    "df.incident_close_datetime = pd.to_datetime(df.incident_close_datetime)\n",
    "#df.first_on_scene_datetime = pd.to_datetime(df.first_on_scene_datetime)\n",
    "\n",
    "#Float conversion\n",
    "df.dispatch_response_seconds_qy = df.dispatch_response_seconds_qy.astype(float)\n",
    "df.incident_response_seconds_qy = df.incident_response_seconds_qy.astype(float)\n",
    "df.incident_travel_tm_seconds_qy = df.incident_travel_tm_seconds_qy.astype(float)\n",
    "df.engines_assigned_quantity = df.engines_assigned_quantity.astype(float)\n",
    "df.ladders_assigned_quantity = df.ladders_assigned_quantity.astype(float)\n",
    "df.other_units_assigned_quantity = df.other_units_assigned_quantity.astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32df4d8c-c61e-4e8c-8068-fdf815cd7402",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f144c5-fdef-4ad1-87c3-6005aa8ea013",
   "metadata": {},
   "source": [
    "## PySpark Transformations ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2cdef4-fd93-4977-9fb8-ba9773ec4b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.sql.functions import to_timestamp, to_date\n",
    "spark = SparkSession.builder.appName(\"Transformations_NYC_Fire_Incidents\").getOrCreate()\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d897a-09bc-402e-9fa8-1854d1f3cf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(spark.sparkContext.parallelize([results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45500c8d-7f3d-444c-8a23-38618a313eaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ea1c09-d9ea-4dea-abb5-7657d0f22bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORIGINAL - Modified with For Loop\n",
    "#Function to clean null values, The function takes in the following paramters: pyspark dataframe, column name to clean, each of the broughs values to switch to.\n",
    "def clean_null_values(df,null_fields_and_values,aggregate_field,boroughs):\n",
    "    \n",
    "    for field in null_fields_and_values:\n",
    "        \n",
    "        df = df.withColumn(\n",
    "        field,\n",
    "        when(col(field).isNull() & (col(aggregate_field) == aggregate_values[0]),null_fields_and_values[field][0])\n",
    "        .when(col(field).isNull() & (col(aggregate_field) == aggregate_values[1]),null_fields_and_values[field][1])\n",
    "        .when(col(field).isNull() & (col(aggregate_field) == aggregate_values[2]),null_fields_and_values[field][2])\n",
    "        .when(col(field).isNull() & (col(aggregate_field) == aggregate_values[3]),null_fields_and_values[field][3])\n",
    "        .when(col(field).isNull() & (col(aggregate_field) == aggregate_values[4]),null_fields_and_values[field][4])\n",
    "        .otherwise(col(field))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "null_fields_and_values = {\"zipcode\":[10451,11201,10001,11004,10301],\n",
    "                          \"policeprecinct\":[40,60,1,100,120],\n",
    "                          \"citycouncildistrict\":[8,33,1,19,49],\n",
    "                          \"communitydistrict\":[201,301,101,401,501],\n",
    "                          \"communityschooldistrict\":[7,13,1,7,31],\n",
    "                          \"congressionaldistrict\":[13,7,7,3,11]}\n",
    "\n",
    "aggregate_field = \"alarm_box_borough\"\n",
    "aggregate_values = [\"BRONX\",\"BROOKLYN\",\"MANHATTAN\",\"QUEENS\",\"RICHMOND / STATEN ISLAND\"]\n",
    "\n",
    "df = clean_null_values(df,null_fields_and_values,aggregate_field,aggregate_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf6c0ae-20b0-4fff-be34-027300e9b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation purposes run one by one\n",
    "df.where(df[\"policeprecinct\"].isNull()).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").count()\n",
    "df.where(df[\"citycouncildistrict\"].isNull()).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").count()\n",
    "df.where(df[\"communitydistrict\"].isNull()).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").count()\n",
    "df.where(df[\"communityschooldistrict\"].isNull()).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").count()\n",
    "df.where(df[\"congressionaldistrict\"].isNull()).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1059ce-ce28-4c45-bd15-f858f67739a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting fields to date time\n",
    "def convert_to_date_time(df,date_fields_to_convert):\n",
    "    for field in date_fields_to_convert:\n",
    "        df = df.withColumn(field, to_timestamp(df[field]))\n",
    "    return df\n",
    "\n",
    "date_fields_to_convert = [\"incident_datetime\",\"first_assignment_datetime\",\"first_activation_datetime\",\"incident_close_datetime\"]\n",
    "\n",
    "df = convert_to_date_time(df,date_fields_to_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f333623-c9d3-4e35-b114-e8c7db5e1ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting fields to floats\n",
    "def convert_to_float(df,date_fields_to_convert):\n",
    "    for field in date_fields_to_convert:\n",
    "        df = df.withColumn(field, df[field].cast(\"float\"))\n",
    "    return df\n",
    "\n",
    "numerical_fields_to_convert = [\"dispatch_response_seconds_qy\",\n",
    "                               \"incident_response_seconds_qy\",\n",
    "                               \"incident_travel_tm_seconds_qy\",\n",
    "                               \"engines_assigned_quantity\",\n",
    "                               \"ladders_assigned_quantity\",\n",
    "                               \"other_units_assigned_quantity\"]\n",
    "\n",
    "df = convert_to_float(df,numerical_fields_to_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead7677a-8dd8-4517-9b87-474004b25a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to categorize the response times and other quantity type fields. This will be used to aggregate data for OLAP usage.\n",
    "from pyspark.sql.functions import max\n",
    "from pyspark.sql.functions import min\n",
    "\n",
    "def categorize_float_fields(df,fields_to_categorize):\n",
    "    \n",
    "    for field in fields_to_categorize:\n",
    "    \n",
    "        # Returns the max response\n",
    "        max_quantity = df.agg(max(field).alias(\"max_response_alias\")).collect()[0]\n",
    "        max_quantity = max_quantity[\"max_response_alias\"] \n",
    "    \n",
    "        # Returns the min quantity\n",
    "        min_quantity = df.agg(min(field).alias(\"min_response_alias\")).collect()[0]\n",
    "        min_quantity = min_quantity[\"min_response_alias\"]\n",
    "    \n",
    "        #Calculates the category interval this is to determine the intervals between each category. 5 Categories were chosen.\n",
    "        category_interval = (max_quantity - min_quantity) / 5\n",
    "        \n",
    "        #Categorizes each quantity column using the range between the max and min\n",
    "        df = df.withColumn(\n",
    "            \"category_\" + field,\n",
    "            when((col(field) == 0),fields_to_categorize[field][0])\n",
    "            .when((col(field) > 0) & (col(field) <= category_interval),fields_to_categorize[field][1])\n",
    "            .when((col(field) > category_interval) & (col(field) <= (category_interval*2)),fields_to_categorize[field][2])\n",
    "            .when((col(field) > (category_interval*2)) & (col(field) <= (category_interval*3)),fields_to_categorize[field][3])\n",
    "            .when((col(field) > (category_interval*3)) & (col(field) <= (category_interval*4)),fields_to_categorize[field][4])\n",
    "            .otherwise(fields_to_categorize[field][5])\n",
    "        )\n",
    "    \n",
    "    return df\n",
    "\n",
    "fields_to_categorize = {\"dispatch_response_seconds_qy\":[\"None\",\"Very Low\",\"Low\",\"Medium\",\"High\",\"Very High\"],\n",
    "    \"incident_response_seconds_qy\":[\"None\",\"Very Low\",\"Low\",\"Medium\",\"High\",\"Very High\"],\n",
    "    \"incident_travel_tm_seconds_qy\":[\"None\",\"Very Low\",\"Low\",\"Medium\",\"High\",\"Very High\"],\n",
    "    \"engines_assigned_quantity\":[\"None\",\"Minimal\",\"Limited\",\"Moderate\",\"Substantial\",\"Abundant\"],\n",
    "    \"ladders_assigned_quantity\":[\"None\",\"Minimal\",\"Limited\",\"Moderate\",\"Substantial\",\"Abundant\"],\n",
    "    \"other_units_assigned_quantity\":[\"None\",\"Minimal\",\"Limited\",\"Moderate\",\"Substantial\",\"Abundant\"]}\n",
    "\n",
    "\n",
    "df = categorize_float_fields(df,fields_to_categorize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd27d61-a706-4cbc-8b65-bc536f2e1660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "#Renaming Columns and Casting to Float Types\n",
    "def clean_column(df,column_name_before,column_name_after):\n",
    "    df = df.withColumnRenamed(column_name_before, column_name_after)\n",
    "    df = df.withColumn(column_name_after, col(column_name_after).cast(\"float\"))\n",
    "    \n",
    "    return df\n",
    "\n",
    "#Calculating Averages for response times by each borough\n",
    "def calculate_averages(df,fields_to_calculate_averages,aggregate_field):\n",
    "    for field in fields_to_calculate_averages:\n",
    "        total_avg = df.groupBy(aggregate_field).agg(avg(field)).alias(\"total_avg_\"+field+\"_per_borough\")\n",
    "        df = df.join(total_avg, on=aggregate_field, how=\"left\")\n",
    "        df = clean_column(df,f'avg({field})',f'total_avg_{field}_per_borough')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "aggregate_field = \"alarm_box_borough\"\n",
    "fields_to_calculate_averages = [\"dispatch_response_seconds_qy\",\"incident_travel_tm_seconds_qy\",\"incident_response_seconds_qy\"]\n",
    "\n",
    "df = calculate_averages(df,fields_to_calculate_averages,aggregate_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8736d02-4d73-463b-af7b-93c9f76b3e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Resources Assigned to an Incident. Total quantity of Engines, Ladders, and Other Units.\n",
    "def sum_fields(df,sum_field_name,fields_to_sum):\n",
    "    df = df.withColumn(\n",
    "        sum_field_name,\n",
    "        col(fields_to_sum[0]) + col(fields_to_sum[1]) + col(fields_to_sum[2])\n",
    "    )\n",
    "    return df\n",
    "\n",
    "sum_field_name = \"total_resources_assigned_quantity\"\n",
    "fields_to_sum = [\"engines_assigned_quantity\",\"ladders_assigned_quantity\",\"other_units_assigned_quantity\"]\n",
    "df = sum_fields(df,sum_field_name,fields_to_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa969d-b267-48ea-960a-51f6e7f9e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eebbe2-716c-44a8-bcf6-df44eca3ac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1597eead-a829-4708-b40a-1d6e8982e766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_temp_file(results):\n",
    "    print(\"hello world\")\n",
    "    #Save to temp folder\n",
    "    current_dir = os.getcwd()\n",
    "    temp_folder = os.path.join(current_dir, \"temp\")\n",
    "\n",
    "    # Create the temp folder if it doesn't exist\n",
    "    if not os.path.exists(temp_folder):\n",
    "        os.makedirs(temp_folder)\n",
    "\n",
    "    # Define the path to the JSON file\n",
    "    file_path = os.path.join(temp_folder, \"temp.json\")\n",
    "\n",
    "    # Write the JSON output to the file\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(results, file, indent=4)\n",
    "\n",
    "def read_temp_file():\n",
    "    # Get the current directory and define the temp folder path\n",
    "    print(\"Reading JSON Temp File to json_data variable\")\n",
    "    current_dir = os.getcwd()\n",
    "    temp_folder = os.path.join(current_dir, \"temp\")\n",
    "    print(current_dir)\n",
    "\n",
    "    # Define the path to the JSON file\n",
    "    file_path = os.path.join(temp_folder, \"temp.json\")\n",
    "    print(\"Printing file path: \")\n",
    "    print(file_path)\n",
    "\n",
    "    # Read the JSON file\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        json_data = json.load(file)\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "def remove_temp_file():\n",
    "    current_dir = os.getcwd()\n",
    "    temp_folder = os.path.join(current_dir, \"temp\")\n",
    "    file_path = os.path.join(temp_folder, \"temp.json\")\n",
    "    # Delete the temporary file\n",
    "    os.remove(file_path)\n",
    "    print(f\"Temporary file deleted: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b14a4c3-a9eb-410f-8902-47c19f47cdd5",
   "metadata": {},
   "source": [
    "#### Official Transformations ^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8340ccee-2260-4c63-87df-28cfddd74320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max\n",
    "from pyspark.sql.functions import min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beb7a70-5352-4d66-86a5-7169c9375b37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# category_ranges_dispatch_response_seconds_qy\n",
    "max_dispatch_response_seconds_qy = df.agg(max(\"dispatch_response_seconds_qy\").alias(\"max_dispatch_response_seconds_qy\")).collect()[0]\n",
    "max_dispatch_response_seconds_qy = max_dispatch_response_seconds_qy[\"max_dispatch_response_seconds_qy\"] \n",
    "\n",
    "min_dispatch_response_seconds_qy = df.agg(min(\"dispatch_response_seconds_qy\").alias(\"max_dispatch_response_seconds_qy\")).collect()[0]\n",
    "min_dispatch_response_seconds_qy = min_dispatch_response_seconds_qy[\"max_dispatch_response_seconds_qy\"]\n",
    "\n",
    "category_ranges_dispatch_response_seconds_qy = (max_dispatch_response_seconds_qy - min_dispatch_response_seconds_qy) / 5\n",
    "\n",
    "#Categorize dispatch_response_seconds_qy Very Low, Low, Medium, High, Very High\n",
    "df = df.withColumn(\n",
    "    \"category_dispatch_response_seconds_qy\",\n",
    "    when((col(\"dispatch_response_seconds_qy\") >= 0) & (col(\"dispatch_response_seconds_qy\") <= category_ranges_dispatch_response_seconds_qy),\"Very Low\")\n",
    "    .when((col(\"dispatch_response_seconds_qy\") > category_ranges_dispatch_response_seconds_qy) & (col(\"dispatch_response_seconds_qy\") <= (category_ranges_dispatch_response_seconds_qy*2)),\"Low\")\n",
    "    .when((col(\"dispatch_response_seconds_qy\") > (category_ranges_dispatch_response_seconds_qy*2)) & (col(\"dispatch_response_seconds_qy\") <= (category_ranges_dispatch_response_seconds_qy*3)),\"Medium\")\n",
    "    .when((col(\"dispatch_response_seconds_qy\") > (category_ranges_dispatch_response_seconds_qy*3)) & (col(\"dispatch_response_seconds_qy\") <= (category_ranges_dispatch_response_seconds_qy*4)),\"High\")\n",
    "    .otherwise(\"Very High\")\n",
    "    #.when(col(\"dispatch_response_seconds_qy\") > (category_ranges_dispatch_response_seconds_qy*4) & (col(\"dispatch_response_seconds_qy\") <= (category_ranges_dispatch_response_seconds_qy*5)),\"Very High\")\n",
    ")\n",
    "\n",
    "df.select(df[\"category_dispatch_response_seconds_qy\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9996c7fd-d820-440b-bc4a-ac6760c3874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select([\"category_other_units_assigned_quantity\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7d5b8-2bd5-42dd-a897-574e5e71f2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae3656-e1be-4cb1-8e9d-5e099768d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"category_engines_assigned_quantity\"].select()\n",
    "df.orderBy(df[\"engines_assigned_quantity\"].desc()).select(df[\"category_engines_assigned_quantity\"],df[\"engines_assigned_quantity\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d183d-377f-4f10-942c-e261f98e3dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01316b2-a71f-4776-9df9-9ab749a82459",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('Temp_Tbl')\n",
    "max_dispatch_response_seconds_qy = spark.sql(\"SELECT max(dispatch_response_seconds_qy) FROM Temp_Tbl\")\n",
    "min_dispatch_response_seconds_qy = spark.sql(\"SELECT max(dispatch_response_seconds_qy) FROM Temp_Tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed2c7a0-eb50-48d7-b6fc-1064ca975b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dispatch_response_seconds_qy.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c43bbb-450b-4b48-ac83-868c754af69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dispatch_response_seconds_qy.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d72f6c-8f6e-4e33-a643-ccec0521764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dispatch_response_seconds_qy.show() / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f461359-1f21-4194-a042-9eb163436650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(df[\"dispatch_response_seconds_qy\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac24d7c-f3a2-46ff-8c78-b3f1f86e4aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length\n",
    "df_with_char_count = df.withColumn(\"char_count\", length(df[\"zipcode\"]))\n",
    "df_with_char_count.where(df_with_char_count[\"char_count\"]>5).select(\"zipcode\",\"char_count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03cf31-2f0b-47a8-821f-faa73a039133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4b077c-b481-4f32-b41b-e808e75d14c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"first_assignment_datetime\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d4f652-cd56-4afd-9864-9c07f451357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('Temp_Tbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263a84ae-0adc-4163-b8bd-8148dc62bd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = spark.sql(\"SELECT * FROM Fire_Incidents_Temp_Tbl where zipcode is null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5225e53f-25f0-451f-b56c-68a768fbde01",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de1233-5d56-41af-b1cc-8ef02aed589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = spark.sql(\"SELECT starfire_incident_id,zipcode,alarm_box_borough FROM Fire_Incidents_Temp_Tbl where starfire_incident_id = 2100422620120017\")\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f8351-9a50-404d-8d93-1bf91aae7e14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.select(\"starfire_incident_id\", \"zipcode\",\"alarm_box_borough\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fdf4a7-a08a-4ca2-8751-7d692469cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df[\"starfire_incident_id\"]==2100422620120017).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f043cea-0b55-418c-bc37-f60c3706ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df[\"starfire_incident_id\"]==2100422620120017).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09356939-7b28-4d1f-8b83-57f7d36b600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df[\"zipcode\"].isNull()).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16237aec-4a91-4ea6-a2fd-1f8a83009fd0",
   "metadata": {},
   "source": [
    "## Postgres Load ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fd991d-5d00-406b-9bc6-41686c6aec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86692e-3d35-498a-8f92-3cae086a7cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the engine postgressql://username:password@host:port/db_name\n",
    "username = 'root'\n",
    "password = 'root'\n",
    "host = \"fire_incidents_db\"\n",
    "port = 5432\n",
    "database = \"fire_incidents\"\n",
    "engine = create_engine(f'postgresql://{username}:{password}@{host}:{port}/{database}')\n",
    "#engine = create_engine(f'postgresql://{username}:{password}@{host_name}:{port}/{database}')\n",
    "#engine = create_engine('postgresql://root:root@fire_incidents_db:5432/fire_incidents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778531de-91b9-453c-a9cb-3f7716b61d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needs to convert fields to date time before loading\n",
    "def convert_to_date_time_using_pands(df,date_fields_to_convert):\n",
    "    for field in date_fields_to_convert:\n",
    "        df[field] = pd.to_datetime(df[field])\n",
    "        \n",
    "    return df\n",
    "\n",
    "date_fields_to_convert = [\"incident_datetime\",\n",
    "                              \"first_assignment_datetime\",\n",
    "                              \"first_activation_datetime\",\n",
    "                              \"incident_close_datetime\",\n",
    "                             \"first_on_scene_datetime\"]\n",
    "\n",
    "df = convert_to_date_time_using_pands(df,date_fields_to_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18242819-4e37-48b3-9bfe-732da556686a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Defines a schema, names it to yellow_taxi_data, and then assigns it to postgres\n",
    "print(pd.io.sql.get_schema(df,name='fire_incidents_schema',con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932c5c2-e3a3-421f-85b5-dc215eafce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates the table in postgres with only the field names. Name = yellow_taxi_data, Engine is the postgres database, if_exists = 'replace' if a table already exists with this name it will replace it\n",
    "df.head(n=0).to_sql(name='fire_incidents_tbl',con=engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0398cc2b-cb01-461c-8c0a-0ebf092da2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "batchsize = 1000\n",
    "def create_batches_of_rows(dataframe,batchsize):\n",
    "    start = 0\n",
    "    while start < len(df) + 1:\n",
    "        yield df.iloc[start:start + batchsize]\n",
    "        start += batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab342479-2126-4871-87f8-fc2e65e0eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a list of batches. Parses the dataframe and the batchsize through the create_batches_of_rows function and sets the variable batches to the list\n",
    "batches = list(create_batches_of_rows(df,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3260e20-ba46-471d-8666-4d8c85fec800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loops through each one of the batches and appends the batch to the postgressql database.\n",
    "counter = 1\n",
    "for batch in batches:\n",
    "    batch.to_sql(name='fire_incidents_tbl', con=engine, if_exists='append')\n",
    "    print(f'Batch Loaded..... {counter}')\n",
    "    counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3abf44-0e46-47f4-a918-9ef65610a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'root'\n",
    "password = 'root'\n",
    "host = \"fire_incidents_db\"\n",
    "port = 5432\n",
    "database = \"fire_incidents\"\n",
    "print(f'postgresql+psycopg2://{username}:{password}@{host}:{port}/{database}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
