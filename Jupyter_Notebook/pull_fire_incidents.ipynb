{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42514d9a-9e37-4a2d-aa0b-93a3b37cd315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from sodapy import Socrata\n",
    "from sqlalchemy import create_engine\n",
    "from time import time\n",
    "import argparse\n",
    "#import psycopg2\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt\n",
    "import requests\n",
    "import pyspark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31709c98-0699-4d0e-935e-b783545e462a",
   "metadata": {},
   "source": [
    "## Calculate Dynamic Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "495facc4-2f75-4428-96cb-7006fad210cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_date_range(execution_date):\n",
    "    # First day of the previous month\n",
    "    first_day = (execution_date.replace(day=1) - timedelta(days=1)).replace(day=1)\n",
    "    \n",
    "    # Last day of the previous month\n",
    "    last_day = execution_date.replace(day=1) - timedelta(days=1)\n",
    "\n",
    "    return first_day.strftime(\"%Y-%m-%d\"), last_day.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b445e23-41f1-43ee-b788-32f643c051bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-01 2025-04-30\n"
     ]
    }
   ],
   "source": [
    "executiondate = datetime(2025,5,5)\n",
    "first_day, last_day = get_date_range(executiondate)\n",
    "print(first_day, last_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a1d8b8-c98b-4cf6-a8eb-0eed87ad3aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-01 2025-03-31\n"
     ]
    }
   ],
   "source": [
    "executiondate = datetime.today()\n",
    "first_day, last_day = get_date_range(executiondate)\n",
    "print(first_day, last_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b28180-0202-4a2b-8afa-a2f5bc58db43",
   "metadata": {},
   "source": [
    "## Extract Via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "143bf28d-3b35-4664-a843-486709c4d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Socrata(\"data.cityofnewyork.us\", \"xoIfIdDlHq6gGzxqLqbUeMpsG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54ce961e-249f-43d1-8435-053914b4a7c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to API\n"
     ]
    }
   ],
   "source": [
    "#Get API between two dates\n",
    "@retry(wait=wait_exponential(multiplier=2, min=2, max=16), stop=stop_after_attempt(5))\n",
    "def get_data_from_api(api_url,datasetid,incident_date_time_from,incident_date_time_to,offset):\n",
    "    # Define the API endpoint\n",
    "    \n",
    "    url = f\"https://{api_url}/resource/{datasetid}.json?$where=incident_datetime >= '{incident_date_time_from}T00:00:00' AND incident_datetime < '{incident_date_time_to}T00:00:00'&$limit=1000&$offset={offset}\"\n",
    "    \n",
    "    # Make the GET request\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        #print(data)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "    \n",
    "    return data\n",
    "try:\n",
    "    \n",
    "    results = get_data_from_api('data.cityofnewyork.us','8m42-w767','2017-01-01','2018-01-01',1000)\n",
    "    df = pd.DataFrame.from_records(results)\n",
    "    offset_counter = 1000\n",
    "    \n",
    "    while len(results) == 1000:\n",
    "        results = get_data_from_api('data.cityofnewyork.us','8m42-w767','2017-01-01','2018-01-01',offset_counter)\n",
    "        df = pd.concat([df, pd.DataFrame.from_records(results)], ignore_index=True)\n",
    "        offset_counter = 1000 + offset_counter\n",
    "        \n",
    "    #df1 = pd.DataFrame.from_records(results)\n",
    "    print(\"Connected to API\")\n",
    "    #print(len(results))\n",
    "    \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Failed to fetch data from API: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a21c2355-49a7-411f-a5a2-d654ac2f9b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(results)\n",
    "df = pd.concat([df, pd.DataFrame.from_records(results)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9638b3c-96d5-4e3b-a34b-f0ee3c64d56c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99ec287e-0a9f-4e0a-8819-2e69acb59cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starfire_incident_id</th>\n",
       "      <th>incident_datetime</th>\n",
       "      <th>alarm_box_borough</th>\n",
       "      <th>alarm_box_number</th>\n",
       "      <th>alarm_box_location</th>\n",
       "      <th>incident_borough</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>policeprecinct</th>\n",
       "      <th>citycouncildistrict</th>\n",
       "      <th>communitydistrict</th>\n",
       "      <th>...</th>\n",
       "      <th>first_activation_datetime</th>\n",
       "      <th>first_on_scene_datetime</th>\n",
       "      <th>incident_close_datetime</th>\n",
       "      <th>valid_dispatch_rspns_time_indc</th>\n",
       "      <th>valid_incident_rspns_time_indc</th>\n",
       "      <th>incident_response_seconds_qy</th>\n",
       "      <th>incident_travel_tm_seconds_qy</th>\n",
       "      <th>engines_assigned_quantity</th>\n",
       "      <th>ladders_assigned_quantity</th>\n",
       "      <th>other_units_assigned_quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1700104690710750</td>\n",
       "      <td>2017-01-01T12:50:56.000</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>469</td>\n",
       "      <td>AVE B &amp; 14 ST</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10009</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-01-01T12:51:52.000</td>\n",
       "      <td>2017-01-01T12:53:53.000</td>\n",
       "      <td>2017-01-01T13:10:22.000</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>177</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700120390150450</td>\n",
       "      <td>2017-01-01T12:52:34.000</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>2039</td>\n",
       "      <td>NORTH CONDUIT AVE. &amp; COHANCY ST.</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11417</td>\n",
       "      <td>106</td>\n",
       "      <td>32</td>\n",
       "      <td>410</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-01-01T12:53:20.000</td>\n",
       "      <td>2017-01-01T12:56:43.000</td>\n",
       "      <td>2017-01-01T13:04:25.000</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>249</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1700152700150450</td>\n",
       "      <td>2017-01-01T12:53:04.000</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>5270</td>\n",
       "      <td>109 AVE &amp; 120 ST</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11419</td>\n",
       "      <td>106</td>\n",
       "      <td>28</td>\n",
       "      <td>410</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-01-01T12:53:32.000</td>\n",
       "      <td>2017-01-01T12:57:16.000</td>\n",
       "      <td>2017-01-01T13:05:13.000</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>252</td>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1700117530110750</td>\n",
       "      <td>2017-01-01T12:53:20.000</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>1753</td>\n",
       "      <td>AMSTERDAM AVE AND 183RD ST</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10033</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-01-01T12:53:58.000</td>\n",
       "      <td>2017-01-01T12:56:45.000</td>\n",
       "      <td>2017-01-01T13:07:20.000</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>205</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1700109930110750</td>\n",
       "      <td>2017-01-01T12:54:00.000</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>993</td>\n",
       "      <td>PARK AVE &amp; 68 ST</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10065</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-01-01T12:54:31.000</td>\n",
       "      <td>2017-01-01T12:57:07.000</td>\n",
       "      <td>2017-01-01T13:16:10.000</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>187</td>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589216</th>\n",
       "      <td>1736578410250800</td>\n",
       "      <td>2017-12-31T23:57:49.000</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>7841</td>\n",
       "      <td>ROOSEVELT AVE &amp; 80 ST</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11372</td>\n",
       "      <td>115</td>\n",
       "      <td>25</td>\n",
       "      <td>403</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-12-31T23:58:18.000</td>\n",
       "      <td>2018-01-01T00:01:03.000</td>\n",
       "      <td>2018-01-01T00:09:55.000</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>194</td>\n",
       "      <td>179</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589217</th>\n",
       "      <td>1736532580141290</td>\n",
       "      <td>2017-12-31T23:57:55.000</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>3258</td>\n",
       "      <td>AVENUE P &amp; E 24 ST</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11229</td>\n",
       "      <td>61</td>\n",
       "      <td>48</td>\n",
       "      <td>315</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-12-31T23:58:37.000</td>\n",
       "      <td>2018-01-01T00:02:08.000</td>\n",
       "      <td>2018-01-01T01:20:58.000</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>253</td>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589218</th>\n",
       "      <td>1736502721511440</td>\n",
       "      <td>2017-12-31T23:58:41.000</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>272</td>\n",
       "      <td>MANGIN &amp; DELANCEY STS</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10002</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-12-31T23:59:13.000</td>\n",
       "      <td>2018-01-01T00:02:14.000</td>\n",
       "      <td>2018-01-01T00:11:48.000</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>213</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589219</th>\n",
       "      <td>1736534410121130</td>\n",
       "      <td>2017-12-31T23:58:46.000</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>3441</td>\n",
       "      <td>CRUGER AVE &amp; ALLERTON AVE</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10467</td>\n",
       "      <td>49</td>\n",
       "      <td>15</td>\n",
       "      <td>211</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-01-01T00:06:55.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01T00:09:35.000</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589220</th>\n",
       "      <td>1736549360150800</td>\n",
       "      <td>2017-12-31T23:59:45.000</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>4936</td>\n",
       "      <td>133 AVE &amp; 125 ST</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11420</td>\n",
       "      <td>106</td>\n",
       "      <td>28</td>\n",
       "      <td>410</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-01-01T00:00:27.000</td>\n",
       "      <td>2018-01-01T00:04:51.000</td>\n",
       "      <td>2018-01-01T00:16:17.000</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>306</td>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>589221 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       starfire_incident_id        incident_datetime alarm_box_borough  \\\n",
       "0          1700104690710750  2017-01-01T12:50:56.000         MANHATTAN   \n",
       "1          1700120390150450  2017-01-01T12:52:34.000            QUEENS   \n",
       "2          1700152700150450  2017-01-01T12:53:04.000            QUEENS   \n",
       "3          1700117530110750  2017-01-01T12:53:20.000         MANHATTAN   \n",
       "4          1700109930110750  2017-01-01T12:54:00.000         MANHATTAN   \n",
       "...                     ...                      ...               ...   \n",
       "589216     1736578410250800  2017-12-31T23:57:49.000            QUEENS   \n",
       "589217     1736532580141290  2017-12-31T23:57:55.000          BROOKLYN   \n",
       "589218     1736502721511440  2017-12-31T23:58:41.000         MANHATTAN   \n",
       "589219     1736534410121130  2017-12-31T23:58:46.000             BRONX   \n",
       "589220     1736549360150800  2017-12-31T23:59:45.000            QUEENS   \n",
       "\n",
       "       alarm_box_number                alarm_box_location incident_borough  \\\n",
       "0                   469                     AVE B & 14 ST        MANHATTAN   \n",
       "1                  2039  NORTH CONDUIT AVE. & COHANCY ST.           QUEENS   \n",
       "2                  5270                  109 AVE & 120 ST           QUEENS   \n",
       "3                  1753        AMSTERDAM AVE AND 183RD ST        MANHATTAN   \n",
       "4                   993                  PARK AVE & 68 ST        MANHATTAN   \n",
       "...                 ...                               ...              ...   \n",
       "589216             7841             ROOSEVELT AVE & 80 ST           QUEENS   \n",
       "589217             3258                AVENUE P & E 24 ST         BROOKLYN   \n",
       "589218              272             MANGIN & DELANCEY STS        MANHATTAN   \n",
       "589219             3441         CRUGER AVE & ALLERTON AVE            BRONX   \n",
       "589220             4936                  133 AVE & 125 ST           QUEENS   \n",
       "\n",
       "       zipcode policeprecinct citycouncildistrict communitydistrict  ...  \\\n",
       "0        10009              9                   2               103  ...   \n",
       "1        11417            106                  32               410  ...   \n",
       "2        11419            106                  28               410  ...   \n",
       "3        10033             34                  10               112  ...   \n",
       "4        10065             19                   4               108  ...   \n",
       "...        ...            ...                 ...               ...  ...   \n",
       "589216   11372            115                  25               403  ...   \n",
       "589217   11229             61                  48               315  ...   \n",
       "589218   10002              7                   2               103  ...   \n",
       "589219   10467             49                  15               211  ...   \n",
       "589220   11420            106                  28               410  ...   \n",
       "\n",
       "       first_activation_datetime  first_on_scene_datetime  \\\n",
       "0        2017-01-01T12:51:52.000  2017-01-01T12:53:53.000   \n",
       "1        2017-01-01T12:53:20.000  2017-01-01T12:56:43.000   \n",
       "2        2017-01-01T12:53:32.000  2017-01-01T12:57:16.000   \n",
       "3        2017-01-01T12:53:58.000  2017-01-01T12:56:45.000   \n",
       "4        2017-01-01T12:54:31.000  2017-01-01T12:57:07.000   \n",
       "...                          ...                      ...   \n",
       "589216   2017-12-31T23:58:18.000  2018-01-01T00:01:03.000   \n",
       "589217   2017-12-31T23:58:37.000  2018-01-01T00:02:08.000   \n",
       "589218   2017-12-31T23:59:13.000  2018-01-01T00:02:14.000   \n",
       "589219   2018-01-01T00:06:55.000                      NaN   \n",
       "589220   2018-01-01T00:00:27.000  2018-01-01T00:04:51.000   \n",
       "\n",
       "        incident_close_datetime valid_dispatch_rspns_time_indc  \\\n",
       "0       2017-01-01T13:10:22.000                              N   \n",
       "1       2017-01-01T13:04:25.000                              N   \n",
       "2       2017-01-01T13:05:13.000                              N   \n",
       "3       2017-01-01T13:07:20.000                              N   \n",
       "4       2017-01-01T13:16:10.000                              N   \n",
       "...                         ...                            ...   \n",
       "589216  2018-01-01T00:09:55.000                              N   \n",
       "589217  2018-01-01T01:20:58.000                              N   \n",
       "589218  2018-01-01T00:11:48.000                              N   \n",
       "589219  2018-01-01T00:09:35.000                              N   \n",
       "589220  2018-01-01T00:16:17.000                              N   \n",
       "\n",
       "       valid_incident_rspns_time_indc incident_response_seconds_qy  \\\n",
       "0                                   Y                          177   \n",
       "1                                   Y                          249   \n",
       "2                                   Y                          252   \n",
       "3                                   Y                          205   \n",
       "4                                   Y                          187   \n",
       "...                               ...                          ...   \n",
       "589216                              Y                          194   \n",
       "589217                              Y                          253   \n",
       "589218                              Y                          213   \n",
       "589219                              N                            0   \n",
       "589220                              Y                          306   \n",
       "\n",
       "       incident_travel_tm_seconds_qy engines_assigned_quantity  \\\n",
       "0                                133                         3   \n",
       "1                                225                         1   \n",
       "2                                241                         1   \n",
       "3                                200                         1   \n",
       "4                                177                         1   \n",
       "...                              ...                       ...   \n",
       "589216                           179                         3   \n",
       "589217                           245                         1   \n",
       "589218                           200                         3   \n",
       "589219                             0                         1   \n",
       "589220                           297                         1   \n",
       "\n",
       "       ladders_assigned_quantity other_units_assigned_quantity  \n",
       "0                              2                             1  \n",
       "1                              1                             2  \n",
       "2                              0                             0  \n",
       "3                              0                             0  \n",
       "4                              0                             0  \n",
       "...                          ...                           ...  \n",
       "589216                         2                             1  \n",
       "589217                         0                             0  \n",
       "589218                         3                             1  \n",
       "589219                         0                             0  \n",
       "589220                         0                             0  \n",
       "\n",
       "[589221 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a89dfd-140b-44e8-bae2-0829fa7b28f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f0cdac-8f37-45b3-849a-9d7956aa9abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(results) == 1000:\n",
    "    try:\n",
    "    #results = client.get(\"8m42-w767\", limit=50)\n",
    "    results = get_data_from_api('data.cityofnewyork.us','8m42-w767','2017-01-01','2018-01-01')\n",
    "    print(\"Connected to API\")\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to fetch data from API: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a5ee9-1947-4a67-94d7-da884d27eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get API between two dates\n",
    "@retry(wait=wait_exponential(multiplier=2, min=2, max=16), stop=stop_after_attempt(5))\n",
    "def get_data_from_api(api_url,datasetid,incident_date_time_from,incident_date_time_to):\n",
    "    # Define the API endpoint\n",
    "    url = f\"https://{api_url}/resource/{datasetid}.json\"\n",
    "    params = {\n",
    "        \"$where\": f\"incident_datetime >= '{incident_date_time_from}T00:00:00' AND incident_datetime < '{incident_date_time_to}T00:00:00'&$limit=1000&$offset=0\"\n",
    "        #\"$where\": f\"incident_datetime between '{incident_date_time_from}T00:00:00' AND '{incident_date_time_to}T00:00:00'\"\n",
    "        #\"$where\": f\"incident_datetime >= '{incident_date_time_from}T00:00:00' AND incident_datetime <= '{incident_date_time_to}T00:00:00'&$limit=1000&$offset=0\"\n",
    "    }\n",
    "    # Make the GET request\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(data)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "    \n",
    "    return data\n",
    "try:\n",
    "    #results = client.get(\"8m42-w767\", limit=50)\n",
    "    results = get_data_from_api('data.cityofnewyork.us','8m42-w767','2010-01-01','2024-01-01')\n",
    "    print(\"Connected to API\")\n",
    "    \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Failed to fetch data from API: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9bf86a-7dc6-447d-b55e-43f64246b8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_exponential(multiplier=2, min=2, max=16), stop=stop_after_attempt(5))\n",
    "def get_data_from_api(client,data_set,limit_rows):\n",
    "    results = client.get(data_set,limit=limit_rows)\n",
    "    return results\n",
    "try:\n",
    "    #results = client.get(\"8m42-w767\", limit=50)\n",
    "    results = get_data_from_api(client,\"8m42-w767\",20)\n",
    "    print(\"Connected to API\")\n",
    "    \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Failed to fetch data from API: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf73de0-db34-4cea-923c-c405af4fdf4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d89f173-6636-4a44-ae98-0750faafd109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "#Save to temp folder\n",
    "current_dir = os.getcwd()\n",
    "temp_folder = os.path.join(current_dir, \"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e8eb5e-42d8-4fc7-8dcd-6dae43e00566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the temp folder if it doesn't exist\n",
    "if not os.path.exists(temp_folder):\n",
    "    os.makedirs(temp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fef43a2-7ba3-45b6-a487-9ad8953bafc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the JSON file\n",
    "file_path = os.path.join(temp_folder, \"output.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b6bdc6-820a-41be-8400-a915d41addc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the JSON output to the file\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(results, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8154a360-c791-4df7-aaa7-0761d78590e8",
   "metadata": {},
   "source": [
    "## Pandas Transformations ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d866251-5081-453f-a59e-d8c1ae95b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99b194b-afb3-456f-8a0c-4e381dc26b50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b157cd1-6ea3-42b3-9787-ebd38a2d27d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b4936-cd73-48cc-889d-3f4049046637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows 390 through 400\n",
    "subset = df.iloc[389:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3525c1-1821-4171-8e1c-90785ab73f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53bc758-957e-4d9a-aca5-899c1a0eba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting fields to correct data types\n",
    "#Date conversion\n",
    "df.incident_datetime = pd.to_datetime(df.incident_datetime)\n",
    "df.first_assignment_datetime = pd.to_datetime(df.first_assignment_datetime)\n",
    "df.first_activation_datetime = pd.to_datetime(df.first_activation_datetime)\n",
    "df.incident_close_datetime = pd.to_datetime(df.incident_close_datetime)\n",
    "#df.first_on_scene_datetime = pd.to_datetime(df.first_on_scene_datetime)\n",
    "\n",
    "#Float conversion\n",
    "df.dispatch_response_seconds_qy = df.dispatch_response_seconds_qy.astype(float)\n",
    "df.incident_response_seconds_qy = df.incident_response_seconds_qy.astype(float)\n",
    "df.incident_travel_tm_seconds_qy = df.incident_travel_tm_seconds_qy.astype(float)\n",
    "df.engines_assigned_quantity = df.engines_assigned_quantity.astype(float)\n",
    "df.ladders_assigned_quantity = df.ladders_assigned_quantity.astype(float)\n",
    "df.other_units_assigned_quantity = df.other_units_assigned_quantity.astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32df4d8c-c61e-4e8c-8068-fdf815cd7402",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f144c5-fdef-4ad1-87c3-6005aa8ea013",
   "metadata": {},
   "source": [
    "## PySpark Transformations ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2cdef4-fd93-4977-9fb8-ba9773ec4b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.sql.functions import to_timestamp, to_date\n",
    "spark = SparkSession.builder.appName(\"Transformations_NYC_Fire_Incidents\").getOrCreate()\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d897a-09bc-402e-9fa8-1854d1f3cf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(spark.sparkContext.parallelize([results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45500c8d-7f3d-444c-8a23-38618a313eaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "087320fe-8afd-4f92-8c01-731377d088b6",
   "metadata": {},
   "source": [
    "#ORIGINAL - Modified with For Loop\n",
    "#Function to clean null values, The function takes in the following paramters: pyspark dataframe, column name to clean, each of the broughs values to switch to.\n",
    "def clean_null_values(df,null_fields_and_values,aggregate_field,boroughs):\n",
    "    \n",
    "    for field in null_fields_and_values:\n",
    "        \n",
    "        df = df.withColumn(\n",
    "        field,\n",
    "        when(col(field).isNull() & (col(aggregate_field) == aggregate_values[0]),null_fields_and_values[field][0])\n",
    "        .when(col(field).isNull() & (col(aggregate_field) == aggregate_values[1]),null_fields_and_values[field][1])\n",
    "        .when(col(field).isNull() & (col(aggregate_field) == aggregate_values[2]),null_fields_and_values[field][2])\n",
    "        .when(col(field).isNull() & (col(aggregate_field) == aggregate_values[3]),null_fields_and_values[field][3])\n",
    "        .when(col(field).isNull() & (col(aggregate_field) == aggregate_values[4]),null_fields_and_values[field][4])\n",
    "        .otherwise(col(field))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "null_fields_and_values = {\"zipcode\":[10451,11201,10001,11004,10301],\n",
    "                          \"policeprecinct\":[40,60,1,100,120],\n",
    "                          \"citycouncildistrict\":[8,33,1,19,49],\n",
    "                          \"communitydistrict\":[201,301,101,401,501],\n",
    "                          \"communityschooldistrict\":[7,13,1,7,31],\n",
    "                          \"congressionaldistrict\":[13,7,7,3,11]}\n",
    "\n",
    "aggregate_field = \"alarm_box_borough\"\n",
    "aggregate_values = [\"BRONX\",\"BROOKLYN\",\"MANHATTAN\",\"QUEENS\",\"RICHMOND / STATEN ISLAND\"]\n",
    "\n",
    "df = clean_null_values(df,null_fields_and_values,aggregate_field,aggregate_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf6c0ae-20b0-4fff-be34-027300e9b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation purposes run one by one\n",
    "df.where(df[\"policeprecinct\"].isNull()).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").count()\n",
    "df.where(df[\"citycouncildistrict\"].isNull()).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").count()\n",
    "df.where(df[\"communitydistrict\"].isNull()).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").count()\n",
    "df.where(df[\"communityschooldistrict\"].isNull()).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").count()\n",
    "df.where(df[\"congressionaldistrict\"].isNull()).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1059ce-ce28-4c45-bd15-f858f67739a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting fields to date time\n",
    "def convert_to_date_time(df,date_fields_to_convert):\n",
    "    for field in date_fields_to_convert:\n",
    "        df = df.withColumn(field, to_timestamp(df[field]))\n",
    "    return df\n",
    "\n",
    "date_fields_to_convert = [\"incident_datetime\",\"first_assignment_datetime\",\"first_activation_datetime\",\"incident_close_datetime\"]\n",
    "\n",
    "df = convert_to_date_time(df,date_fields_to_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f333623-c9d3-4e35-b114-e8c7db5e1ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting fields to floats\n",
    "def convert_to_float(df,date_fields_to_convert):\n",
    "    for field in date_fields_to_convert:\n",
    "        df = df.withColumn(field, df[field].cast(\"float\"))\n",
    "    return df\n",
    "\n",
    "numerical_fields_to_convert = [\"dispatch_response_seconds_qy\",\n",
    "                               \"incident_response_seconds_qy\",\n",
    "                               \"incident_travel_tm_seconds_qy\",\n",
    "                               \"engines_assigned_quantity\",\n",
    "                               \"ladders_assigned_quantity\",\n",
    "                               \"other_units_assigned_quantity\"]\n",
    "\n",
    "df = convert_to_float(df,numerical_fields_to_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead7677a-8dd8-4517-9b87-474004b25a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to categorize the response times and other quantity type fields. This will be used to aggregate data for OLAP usage.\n",
    "from pyspark.sql.functions import max\n",
    "from pyspark.sql.functions import min\n",
    "\n",
    "def categorize_float_fields(df,fields_to_categorize):\n",
    "    \n",
    "    for field in fields_to_categorize:\n",
    "    \n",
    "        # Returns the max response\n",
    "        max_quantity = df.agg(max(field).alias(\"max_response_alias\")).collect()[0]\n",
    "        max_quantity = max_quantity[\"max_response_alias\"] \n",
    "    \n",
    "        # Returns the min quantity\n",
    "        min_quantity = df.agg(min(field).alias(\"min_response_alias\")).collect()[0]\n",
    "        min_quantity = min_quantity[\"min_response_alias\"]\n",
    "    \n",
    "        #Calculates the category interval this is to determine the intervals between each category. 5 Categories were chosen.\n",
    "        category_interval = (max_quantity - min_quantity) / 5\n",
    "        \n",
    "        #Categorizes each quantity column using the range between the max and min\n",
    "        df = df.withColumn(\n",
    "            \"category_\" + field,\n",
    "            when((col(field) == 0),fields_to_categorize[field][0])\n",
    "            .when((col(field) > 0) & (col(field) <= category_interval),fields_to_categorize[field][1])\n",
    "            .when((col(field) > category_interval) & (col(field) <= (category_interval*2)),fields_to_categorize[field][2])\n",
    "            .when((col(field) > (category_interval*2)) & (col(field) <= (category_interval*3)),fields_to_categorize[field][3])\n",
    "            .when((col(field) > (category_interval*3)) & (col(field) <= (category_interval*4)),fields_to_categorize[field][4])\n",
    "            .otherwise(fields_to_categorize[field][5])\n",
    "        )\n",
    "    \n",
    "    return df\n",
    "\n",
    "fields_to_categorize = {\"dispatch_response_seconds_qy\":[\"None\",\"Very Low\",\"Low\",\"Medium\",\"High\",\"Very High\"],\n",
    "    \"incident_response_seconds_qy\":[\"None\",\"Very Low\",\"Low\",\"Medium\",\"High\",\"Very High\"],\n",
    "    \"incident_travel_tm_seconds_qy\":[\"None\",\"Very Low\",\"Low\",\"Medium\",\"High\",\"Very High\"],\n",
    "    \"engines_assigned_quantity\":[\"None\",\"Minimal\",\"Limited\",\"Moderate\",\"Substantial\",\"Abundant\"],\n",
    "    \"ladders_assigned_quantity\":[\"None\",\"Minimal\",\"Limited\",\"Moderate\",\"Substantial\",\"Abundant\"],\n",
    "    \"other_units_assigned_quantity\":[\"None\",\"Minimal\",\"Limited\",\"Moderate\",\"Substantial\",\"Abundant\"]}\n",
    "\n",
    "\n",
    "df = categorize_float_fields(df,fields_to_categorize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd27d61-a706-4cbc-8b65-bc536f2e1660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "#Renaming Columns and Casting to Float Types\n",
    "def clean_column(df,column_name_before,column_name_after):\n",
    "    df = df.withColumnRenamed(column_name_before, column_name_after)\n",
    "    df = df.withColumn(column_name_after, col(column_name_after).cast(\"float\"))\n",
    "    \n",
    "    return df\n",
    "\n",
    "#Calculating Averages for response times by each borough\n",
    "def calculate_averages(df,fields_to_calculate_averages,aggregate_field):\n",
    "    for field in fields_to_calculate_averages:\n",
    "        total_avg = df.groupBy(aggregate_field).agg(avg(field)).alias(\"total_avg_\"+field+\"_per_borough\")\n",
    "        df = df.join(total_avg, on=aggregate_field, how=\"left\")\n",
    "        df = clean_column(df,f'avg({field})',f'total_avg_{field}_per_borough')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "aggregate_field = \"alarm_box_borough\"\n",
    "fields_to_calculate_averages = [\"dispatch_response_seconds_qy\",\"incident_travel_tm_seconds_qy\",\"incident_response_seconds_qy\"]\n",
    "\n",
    "df = calculate_averages(df,fields_to_calculate_averages,aggregate_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8736d02-4d73-463b-af7b-93c9f76b3e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Resources Assigned to an Incident. Total quantity of Engines, Ladders, and Other Units.\n",
    "def sum_fields(df,sum_field_name,fields_to_sum):\n",
    "    df = df.withColumn(\n",
    "        sum_field_name,\n",
    "        col(fields_to_sum[0]) + col(fields_to_sum[1]) + col(fields_to_sum[2])\n",
    "    )\n",
    "    return df\n",
    "\n",
    "sum_field_name = \"total_resources_assigned_quantity\"\n",
    "fields_to_sum = [\"engines_assigned_quantity\",\"ladders_assigned_quantity\",\"other_units_assigned_quantity\"]\n",
    "df = sum_fields(df,sum_field_name,fields_to_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa969d-b267-48ea-960a-51f6e7f9e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eebbe2-716c-44a8-bcf6-df44eca3ac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1597eead-a829-4708-b40a-1d6e8982e766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_temp_file(results):\n",
    "    print(\"hello world\")\n",
    "    #Save to temp folder\n",
    "    current_dir = os.getcwd()\n",
    "    temp_folder = os.path.join(current_dir, \"temp\")\n",
    "\n",
    "    # Create the temp folder if it doesn't exist\n",
    "    if not os.path.exists(temp_folder):\n",
    "        os.makedirs(temp_folder)\n",
    "\n",
    "    # Define the path to the JSON file\n",
    "    file_path = os.path.join(temp_folder, \"temp.json\")\n",
    "\n",
    "    # Write the JSON output to the file\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(results, file, indent=4)\n",
    "\n",
    "def read_temp_file():\n",
    "    # Get the current directory and define the temp folder path\n",
    "    print(\"Reading JSON Temp File to json_data variable\")\n",
    "    current_dir = os.getcwd()\n",
    "    temp_folder = os.path.join(current_dir, \"temp\")\n",
    "    print(current_dir)\n",
    "\n",
    "    # Define the path to the JSON file\n",
    "    file_path = os.path.join(temp_folder, \"temp.json\")\n",
    "    print(\"Printing file path: \")\n",
    "    print(file_path)\n",
    "\n",
    "    # Read the JSON file\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        json_data = json.load(file)\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "def remove_temp_file():\n",
    "    current_dir = os.getcwd()\n",
    "    temp_folder = os.path.join(current_dir, \"temp\")\n",
    "    file_path = os.path.join(temp_folder, \"temp.json\")\n",
    "    # Delete the temporary file\n",
    "    os.remove(file_path)\n",
    "    print(f\"Temporary file deleted: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b14a4c3-a9eb-410f-8902-47c19f47cdd5",
   "metadata": {},
   "source": [
    "#### Official Transformations ^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8340ccee-2260-4c63-87df-28cfddd74320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max\n",
    "from pyspark.sql.functions import min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beb7a70-5352-4d66-86a5-7169c9375b37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# category_ranges_dispatch_response_seconds_qy\n",
    "max_dispatch_response_seconds_qy = df.agg(max(\"dispatch_response_seconds_qy\").alias(\"max_dispatch_response_seconds_qy\")).collect()[0]\n",
    "max_dispatch_response_seconds_qy = max_dispatch_response_seconds_qy[\"max_dispatch_response_seconds_qy\"] \n",
    "\n",
    "min_dispatch_response_seconds_qy = df.agg(min(\"dispatch_response_seconds_qy\").alias(\"max_dispatch_response_seconds_qy\")).collect()[0]\n",
    "min_dispatch_response_seconds_qy = min_dispatch_response_seconds_qy[\"max_dispatch_response_seconds_qy\"]\n",
    "\n",
    "category_ranges_dispatch_response_seconds_qy = (max_dispatch_response_seconds_qy - min_dispatch_response_seconds_qy) / 5\n",
    "\n",
    "#Categorize dispatch_response_seconds_qy Very Low, Low, Medium, High, Very High\n",
    "df = df.withColumn(\n",
    "    \"category_dispatch_response_seconds_qy\",\n",
    "    when((col(\"dispatch_response_seconds_qy\") >= 0) & (col(\"dispatch_response_seconds_qy\") <= category_ranges_dispatch_response_seconds_qy),\"Very Low\")\n",
    "    .when((col(\"dispatch_response_seconds_qy\") > category_ranges_dispatch_response_seconds_qy) & (col(\"dispatch_response_seconds_qy\") <= (category_ranges_dispatch_response_seconds_qy*2)),\"Low\")\n",
    "    .when((col(\"dispatch_response_seconds_qy\") > (category_ranges_dispatch_response_seconds_qy*2)) & (col(\"dispatch_response_seconds_qy\") <= (category_ranges_dispatch_response_seconds_qy*3)),\"Medium\")\n",
    "    .when((col(\"dispatch_response_seconds_qy\") > (category_ranges_dispatch_response_seconds_qy*3)) & (col(\"dispatch_response_seconds_qy\") <= (category_ranges_dispatch_response_seconds_qy*4)),\"High\")\n",
    "    .otherwise(\"Very High\")\n",
    "    #.when(col(\"dispatch_response_seconds_qy\") > (category_ranges_dispatch_response_seconds_qy*4) & (col(\"dispatch_response_seconds_qy\") <= (category_ranges_dispatch_response_seconds_qy*5)),\"Very High\")\n",
    ")\n",
    "\n",
    "df.select(df[\"category_dispatch_response_seconds_qy\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9996c7fd-d820-440b-bc4a-ac6760c3874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select([\"category_other_units_assigned_quantity\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7d5b8-2bd5-42dd-a897-574e5e71f2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae3656-e1be-4cb1-8e9d-5e099768d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"category_engines_assigned_quantity\"].select()\n",
    "df.orderBy(df[\"engines_assigned_quantity\"].desc()).select(df[\"category_engines_assigned_quantity\"],df[\"engines_assigned_quantity\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d183d-377f-4f10-942c-e261f98e3dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01316b2-a71f-4776-9df9-9ab749a82459",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('Temp_Tbl')\n",
    "max_dispatch_response_seconds_qy = spark.sql(\"SELECT max(dispatch_response_seconds_qy) FROM Temp_Tbl\")\n",
    "min_dispatch_response_seconds_qy = spark.sql(\"SELECT max(dispatch_response_seconds_qy) FROM Temp_Tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed2c7a0-eb50-48d7-b6fc-1064ca975b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dispatch_response_seconds_qy.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c43bbb-450b-4b48-ac83-868c754af69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dispatch_response_seconds_qy.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d72f6c-8f6e-4e33-a643-ccec0521764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dispatch_response_seconds_qy.show() / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f461359-1f21-4194-a042-9eb163436650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(df[\"dispatch_response_seconds_qy\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac24d7c-f3a2-46ff-8c78-b3f1f86e4aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length\n",
    "df_with_char_count = df.withColumn(\"char_count\", length(df[\"zipcode\"]))\n",
    "df_with_char_count.where(df_with_char_count[\"char_count\"]>5).select(\"zipcode\",\"char_count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03cf31-2f0b-47a8-821f-faa73a039133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4b077c-b481-4f32-b41b-e808e75d14c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"first_assignment_datetime\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d4f652-cd56-4afd-9864-9c07f451357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('Temp_Tbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263a84ae-0adc-4163-b8bd-8148dc62bd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = spark.sql(\"SELECT * FROM Fire_Incidents_Temp_Tbl where zipcode is null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5225e53f-25f0-451f-b56c-68a768fbde01",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de1233-5d56-41af-b1cc-8ef02aed589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = spark.sql(\"SELECT starfire_incident_id,zipcode,alarm_box_borough FROM Fire_Incidents_Temp_Tbl where starfire_incident_id = 2100422620120017\")\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f8351-9a50-404d-8d93-1bf91aae7e14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.select(\"starfire_incident_id\", \"zipcode\",\"alarm_box_borough\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fdf4a7-a08a-4ca2-8751-7d692469cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df[\"starfire_incident_id\"]==2100422620120017).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f043cea-0b55-418c-bc37-f60c3706ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df[\"starfire_incident_id\"]==2100422620120017).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09356939-7b28-4d1f-8b83-57f7d36b600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df[\"zipcode\"].isNull()).select(\"starfire_incident_id\",\"zipcode\",\"alarm_box_borough\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16237aec-4a91-4ea6-a2fd-1f8a83009fd0",
   "metadata": {},
   "source": [
    "## Postgres Load ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fd991d-5d00-406b-9bc6-41686c6aec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86692e-3d35-498a-8f92-3cae086a7cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the engine postgressql://username:password@host:port/db_name\n",
    "username = 'root'\n",
    "password = 'root'\n",
    "host = \"fire_incidents_db\"\n",
    "port = 5432\n",
    "database = \"fire_incidents\"\n",
    "engine = create_engine(f'postgresql://{username}:{password}@{host}:{port}/{database}')\n",
    "#engine = create_engine(f'postgresql://{username}:{password}@{host_name}:{port}/{database}')\n",
    "#engine = create_engine('postgresql://root:root@fire_incidents_db:5432/fire_incidents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778531de-91b9-453c-a9cb-3f7716b61d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needs to convert fields to date time before loading\n",
    "def convert_to_date_time_using_pands(df,date_fields_to_convert):\n",
    "    for field in date_fields_to_convert:\n",
    "        df[field] = pd.to_datetime(df[field])\n",
    "        \n",
    "    return df\n",
    "\n",
    "date_fields_to_convert = [\"incident_datetime\",\n",
    "                              \"first_assignment_datetime\",\n",
    "                              \"first_activation_datetime\",\n",
    "                              \"incident_close_datetime\",\n",
    "                             \"first_on_scene_datetime\"]\n",
    "\n",
    "df = convert_to_date_time_using_pands(df,date_fields_to_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18242819-4e37-48b3-9bfe-732da556686a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Defines a schema, names it to fire_incidents_schema, and then assigns it to postgres\n",
    "print(pd.io.sql.get_schema(df,name='fire_incidents_schema',con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932c5c2-e3a3-421f-85b5-dc215eafce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates the table in postgres with only the field names. Name = yellow_taxi_data, Engine is the postgres database, if_exists = 'replace' if a table already exists with this name it will replace it\n",
    "df.head(n=0).to_sql(name='fire_incidents_tbl',con=engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0398cc2b-cb01-461c-8c0a-0ebf092da2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "batchsize = 1000\n",
    "def create_batches_of_rows(dataframe,batchsize):\n",
    "    start = 0\n",
    "    while start < len(df) + 1:\n",
    "        yield df.iloc[start:start + batchsize]\n",
    "        start += batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab342479-2126-4871-87f8-fc2e65e0eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a list of batches. Parses the dataframe and the batchsize through the create_batches_of_rows function and sets the variable batches to the list\n",
    "batches = list(create_batches_of_rows(df,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3260e20-ba46-471d-8666-4d8c85fec800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loops through each one of the batches and appends the batch to the postgressql database.\n",
    "counter = 1\n",
    "for batch in batches:\n",
    "    batch.to_sql(name='fire_incidents_tbl', con=engine, if_exists='append')\n",
    "    print(f'Batch Loaded..... {counter}')\n",
    "    counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3abf44-0e46-47f4-a918-9ef65610a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'root'\n",
    "password = 'root'\n",
    "host = \"fire_incidents_db\"\n",
    "port = 5432\n",
    "database = \"fire_incidents\"\n",
    "print(f'postgresql+psycopg2://{username}:{password}@{host}:{port}/{database}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
