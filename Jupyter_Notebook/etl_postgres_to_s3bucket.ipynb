{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e632b788-7561-4ede-9dbf-c13eb8bdcfc5",
   "metadata": {},
   "source": [
    "## Extract from Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e13681c-5581-4efc-b239-844cd113523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import csv\n",
    "import boto3\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcb69069-a1eb-4551-b7f8-0bbad62f9a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "database='fire_incidents_db'\n",
    "user_name='root'\n",
    "pwd='root'\n",
    "host_name='fire_incidents_db_container'\n",
    "port_number=5432\n",
    "fire_incidents_tbl_name='fire_incidents_tbl'\n",
    "traffic_tbl_name='nyc_traffic_tbl'\n",
    "fire_incidents_data_name='nyc_fire_incidents_data'\n",
    "traffic_data_name='nyc_traffic_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02a9e1b0-6a65-42a8-88e6-f82e8750e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data_to_csv(database,user_name,pwd,host_name,port_number,tbl_name,data_name):\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=database,\n",
    "        user=user_name,\n",
    "        password=pwd,\n",
    "        host=host_name,\n",
    "        port=port_number\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT * FROM \" + f'{tbl_name}')\n",
    "    \n",
    "    with open('./temp_csv_files/exported_' + f'{data_name}'+'.csv', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([i[0] for i in cursor.description])  # Write headers\n",
    "        writer.writerows(cursor.fetchall())  # Write data\n",
    "    \n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8b2c641-620c-4bcc-b0c4-974a3873c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export nyc fire incidents data\n",
    "export_data_to_csv(database,user_name,pwd,host_name,port_number,fire_incidents_tbl_name,fire_incidents_data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b35871c1-724c-4807-905f-c0e8d73641cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export nyc traffic incident data\n",
    "export_data_to_csv(database,user_name,pwd,host_name,port_number,traffic_tbl_name,traffic_data_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b6cec2-b50e-4c03-9081-7d33994d3481",
   "metadata": {},
   "source": [
    "## Upload CSV File to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8fa5e3e-84cb-4771-8f4b-22563c46c761",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This may be the preferred approach as opposed to the above\n",
    "sts_client = boto3.client('sts')\n",
    "\n",
    "# Assume the IAM role\n",
    "assumed_role = sts_client.assume_role(\n",
    "    RoleArn=\"arn:aws:iam::564001313146:role/S3AccessRoleForNYCFireIncidentsProj\",\n",
    "    RoleSessionName=\"MyS3Session\"\n",
    ")\n",
    "\n",
    "# Extract temporary credentials\n",
    "credentials = assumed_role['Credentials']\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=credentials['AccessKeyId'],\n",
    "    aws_secret_access_key=credentials['SecretAccessKey'],\n",
    "    aws_session_token=credentials['SessionToken']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4d3d6f9-6fe7-4dc1-99da-d53a92e57f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = ['nyc_fire_incidents_data','nyc_traffic_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3c4b8a7-4a1c-43c4-9e4e-e30e860e7458",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_exponential(multiplier=2, min=2, max=16), stop=stop_after_attempt(5))\n",
    "def upload_to_s3():\n",
    "    for name in data_name:\n",
    "        s3_client.upload_file('./temp_csv_files/exported_' + f'{name}' + '.csv', 'nyc-fire-incidents-s3', 'exported_' + f'{name}' + '.csv')\n",
    "        print(\"File uploaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "667260d6-9892-4106-8516-5f7a74850d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully!\n",
      "File uploaded successfully!\n",
      "Uploaded Files to S3!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    upload_to_s3()\n",
    "    print(\"Uploaded Files to S3!\")\n",
    "    \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Failed to upload to S3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280b22b1-e039-46fa-a1cd-756761c3a530",
   "metadata": {},
   "source": [
    "## Load Data from s3 to Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d03574-fe26-4541-8512-a910f71a78dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "COPY your_redshift_table\n",
    "FROM 's3://your_bucket_name/exported_data.csv'\n",
    "IAM_ROLE 'arn:aws:iam::your_account_id:role/your_redshift_role'\n",
    "CSV\n",
    "IGNOREHEADER 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a172ad1-ff38-476c-b190-794738ce7d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "# Define your Redshift credentials\n",
    "redshift_host = \"your-redshift-cluster-endpoint\"\n",
    "redshift_port = 5439  # Default Redshift port\n",
    "redshift_dbname = \"your_database_name\"\n",
    "redshift_user = \"your_username\"\n",
    "redshift_password = \"your_password\"\n",
    "\n",
    "# Define your COPY command parameters\n",
    "copy_command = \"\"\"\n",
    "COPY your_redshift_table\n",
    "FROM 's3://your_bucket_name/exported_data.csv'\n",
    "IAM_ROLE 'arn:aws:iam::your_account_id:role/your_redshift_role'\n",
    "CSV\n",
    "IGNOREHEADER 1;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Establish a connection to Redshift\n",
    "    connection = psycopg2.connect(\n",
    "        dbname=redshift_dbname,\n",
    "        user=redshift_user,\n",
    "        password=redshift_password,\n",
    "        host=redshift_host,\n",
    "        port=redshift_port\n",
    "    )\n",
    "    connection.autocommit = True  # Auto-commit for COPY command\n",
    "\n",
    "    # Create a cursor object to execute the query\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Execute the COPY command\n",
    "    cursor.execute(sql.SQL(copy_command))\n",
    "\n",
    "    print(\"COPY command executed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    # Clean up and close the connection\n",
    "    if connection:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"Connection closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e71fa7-cf13-48b0-bb3a-325f67beb889",
   "metadata": {},
   "source": [
    "## DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2226944a-b677-419a-9d81-180047b491f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from airflow.providers.postgres.operators.postgres import PostgresOperator\n",
    "from airflow.providers.amazon.aws.hooks.s3 import S3Hook\n",
    "from airflow.providers.amazon.aws.hooks.redshift import RedshiftHook\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the DAG\n",
    "default_args = {'start_date': datetime(2025, 3, 22)}\n",
    "dag = DAG('postgres_to_redshift', default_args=default_args, schedule_interval='@daily')\n",
    "\n",
    "# Task 1: Export PostgreSQL Data\n",
    "export_task = PythonOperator(\n",
    "    task_id='export_postgres_to_csv',\n",
    "    python_callable=export_data_to_csv,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Task 2: Upload CSV to S3\n",
    "upload_task = PythonOperator(\n",
    "    task_id='upload_csv_to_s3',\n",
    "    python_callable=upload_to_s3,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Task 3: Load to Redshift\n",
    "redshift_task = PostgresOperator(\n",
    "    task_id='load_to_redshift',\n",
    "    postgres_conn_id='redshift_default',\n",
    "    sql=\"\"\"\n",
    "        COPY your_redshift_table\n",
    "        FROM 's3://your_bucket_name/exported_data.csv'\n",
    "        IAM_ROLE 'arn:aws:iam::your_account_id:role/your_redshift_role'\n",
    "        CSV\n",
    "        IGNOREHEADER 1;\n",
    "    \"\"\",\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Define Task Dependencies\n",
    "export_task >> upload_task >> redshift_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6cae3c-0e21-40ba-b045-bbcfc590253f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd41ddab-da9f-4877-897f-687ec80dd863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37600d95-f743-4483-ad8c-b6bf6a11ed3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e9cfa5-20d1-4b3d-954d-ac728eb1066e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
