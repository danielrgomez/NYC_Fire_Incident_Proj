{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e669560f-e405-4109-b470-235f1f112515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from sodapy import Socrata\n",
    "from sqlalchemy import create_engine\n",
    "from time import time\n",
    "import argparse\n",
    "#import psycopg2\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt\n",
    "import requests\n",
    "import pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4164b1d4-3801-4eb7-905e-b3d3d3086942",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Socrata(\"data.cityofnewyork.us\", \"token_alphanumeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7043e621-6341-407c-992e-f6a2979bfe27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get API between two dates\n",
    "@retry(wait=wait_exponential(multiplier=2, min=2, max=16), stop=stop_after_attempt(5))\n",
    "def get_data_from_api(api_url,datasetid,year_from,year_to):\n",
    "    # Define the API endpoint\n",
    "    url = f\"https://{api_url}/resource/{datasetid}.json\"\n",
    "    params = {\n",
    "        \"$where\": f\"yr >= '{year_from}' AND yr <= '{year_to}'\"\n",
    "    }\n",
    "    # Make the GET request\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(data)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "    \n",
    "    return data\n",
    "try:\n",
    "    #results = client.get(\"8m42-w767\", limit=50)\n",
    "    results = get_data_from_api('data.cityofnewyork.us','7ym2-wayt',2021,2021)\n",
    "    print(\"Connected to API\")\n",
    "    \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Failed to fetch data from API: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c2791-0a2c-4695-b12e-1f10b90542ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a434cb-a77d-48f1-aecc-43b7a8c1743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_exponential(multiplier=2, min=2, max=16), stop=stop_after_attempt(5))\n",
    "def get_data_from_api(client,data_set,limit_rows):\n",
    "    results = client.get(data_set,limit=limit_rows)\n",
    "    return results\n",
    "try:\n",
    "    #results = client.get(\"8m42-w767\", limit=50)\n",
    "    results = get_data_from_api(client,\"7ym2-wayt\",10000)\n",
    "    print(\"Connected to API\")\n",
    "    \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Failed to fetch data from API: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46376f6d-2523-49e7-b233-5757472710a0",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c852171-f172-47b2-ad1b-4ff8c8ffa5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8534d38-4eb9-4694-b416-f275f07194cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ae320-98d6-47b5-91ce-fbf2e2e48f1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49fed7f-0649-4f55-a359-e1649c5e36a7",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e017adc3-a9d3-4540-ab07-746ca048b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, col, to_timestamp, to_date, to_timestamp, concat, lit, upper, length\n",
    "#from pyspark.sql.functions import to_timestamp, to_date, to_timestamp\n",
    "spark = SparkSession.builder.appName(\"Transformations_NYC_Traffic_Data\").getOrCreate()\n",
    "print(spark.version)\n",
    "#from pyspark.sql.functions import concat, lit, initcap\n",
    "#from pyspark.sql.functions import length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7639e00a-a674-4cd4-9da5-c4fd3e3edd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(spark.sparkContext.parallelize([results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f89e048-211c-45a4-86f9-0d7c3f488f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46920a2-563d-43ad-9a6f-db9a081b2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('Temp_Tbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d91484e-d009-4cb0-958d-2c2eac8f7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = spark.sql(\"SELECT boro,street,sum(vol),yr,m,d,hh,mm FROM Temp_Tbl where yr = 2021 Group By boro,street,yr,m,d,hh,mm order by street,yr,m,d,hh,mm asc;\")\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c52385e-6114-4522-81c7-bfdfb6f63d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = spark.sql(\"SELECT yr,m,count(m) FROM Temp_Tbl where yr = 2021 Group By yr,m order by yr,m asc;\")\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfd645d-84f1-459a-b91b-5e1828cdf5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up month column\n",
    "df = df.withColumn(\n",
    "        'm',\n",
    "        when(length(df.m) == 1 ,concat(lit(\"0\"),df.m))\n",
    "        .otherwise(df.m))\n",
    "#Clean up day column\n",
    "df = df.withColumn(\n",
    "        'd',\n",
    "        when(length(df.d) == 1 ,concat(lit(\"0\"),df.d))\n",
    "        .otherwise(df.d))\n",
    "#Clean up month column\n",
    "df = df.withColumn(\n",
    "        'hh',\n",
    "        when(length(df.hh) == 1 ,concat(lit(\"0\"),df.hh))\n",
    "        .otherwise(df.hh))\n",
    "#Clean up day column\n",
    "df = df.withColumn(\n",
    "        'mm',\n",
    "        when(length(df.mm) == 1 ,concat(lit(\"0\"),df.mm))\n",
    "        .otherwise(df.mm))\n",
    "\n",
    "#Create new field called report_date_time which concatenates yr,m,d,hh,mm and converts to datetime field in dataframe\n",
    "df = df.withColumn(\"report_date_time\",concat(df.yr,lit(\"-\"),df.m,lit(\"-\"),df.d,lit(\" \"),df.hh,lit(\":\"),df.mm,lit(\":00\")))\n",
    "df = df.withColumn(\"report_date_time\", to_timestamp(df.report_date_time, \"yyyy-MM-dd HH:mm:ss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ed2679-2782-4619-8894-9099437117a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Borough Upper Case\n",
    "df = df.withColumn(\"boro\", upper(df.boro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dfc7d5-0217-4fe8-9c8b-5793962fdcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert vol to integer\n",
    "df = df.withColumn('vol', df['vol'].cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe81f0c-c4ed-45bb-a715-a94db4413bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c536c7f-d60e-426c-8e46-0ccf9694b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('Temp_Tbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c320b2f8-e3e4-4fdd-bedc-c8529020f565",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = spark.sql(\"SELECT vol,yr,m,d,hh,dd FROM Temp_Tbl limit 5;\")\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e846353e-2cb5-4629-8287-b276b9f0c078",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = spark.sql(\"SELECT report_time,report_date,yr,m,d,hh,mm FROM Temp_Tbl order by d desc limit 5;\")\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820a79c-5f80-4f9f-9ef5-845774a0a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410390e2-d06c-4180-8dbc-a5764c7a7e69",
   "metadata": {},
   "source": [
    "## Postgres Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3743da-4feb-4e7d-b242-dfb782dd3ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec4556-66b2-44cd-9899-61c589273c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the engine postgressql://username:password@host:port/db_name\n",
    "username = 'root'\n",
    "password = 'root'\n",
    "host = \"fire_incidents_db\"\n",
    "port = 5432\n",
    "database = \"fire_incidents\"\n",
    "engine = create_engine(f'postgresql://{username}:{password}@{host}:{port}/{database}')\n",
    "#engine = create_engine(f'postgresql://{username}:{password}@{host_name}:{port}/{database}')\n",
    "#engine = create_engine('postgresql://root:root@fire_incidents_db:5432/fire_incidents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd6e28f-559d-47b7-9076-767479c48f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d21d79-0948-4dd5-b4b1-d470258d0320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Defines a schema, names it to fire_incidents_schema, and then assigns it to postgres\n",
    "print(pd.io.sql.get_schema(pandas_df,name='fire_incidents_schema',con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695e1930-b8ac-4fe8-bc6c-9a89fe8a8cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates the table in postgres with only the field names. Name = yellow_taxi_data, Engine is the postgres database, if_exists = 'replace' if a table already exists with this name it will replace it\n",
    "df.head(n=0).to_sql(name='nyc_traffic_tbl',con=engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc99032-e38d-47fd-b6a5-86d222beeaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "batchsize = 1000\n",
    "def create_batches_of_rows(dataframe,batchsize):\n",
    "    start = 0\n",
    "    while start < len(df) + 1:\n",
    "        yield df.iloc[start:start + batchsize]\n",
    "        start += batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e326de-3ccc-468d-b946-1320ca953cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a list of batches. Parses the dataframe and the batchsize through the create_batches_of_rows function and sets the variable batches to the list\n",
    "batches = list(create_batches_of_rows(df,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f305aad-4d09-4ae9-b396-9f3f888abf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loops through each one of the batches and appends the batch to the postgressql database.\n",
    "counter = 1\n",
    "for batch in batches:\n",
    "    batch.to_sql(name='nyc_traffic_tbl', con=engine, if_exists='append')\n",
    "    print(f'Batch Loaded..... {counter}')\n",
    "    counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339f1143-191b-4fec-94aa-2c3fe589eea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddaba71-2004-4b0e-a023-7632d467e37b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d44b8b-7501-4742-9392-4ee6b5eb3312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699cad42-93a0-4039-b24f-80c6edb70951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f6a4e-8776-402e-90da-bb90f99ccd45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
